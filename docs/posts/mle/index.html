<!DOCTYPE HTML>


<script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><script type="text/javascript">
    window.MathJax = {
        tex: {
            inlineMath: [['$', '$']],
            displayMath: [['$$', '$$']]
        }
    };
</script>
<script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.js">
</script>

<html lang="en">
	<head>
	  <title>(Un)biased Point Estimation</title>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<meta name="referrer" content="origin">

	

    <meta name="description" content="Senior Data Scientist
Understanding Complexity Through Data and Statistics">
    
    <meta name="generator" content="Hugo 0.138.0">

    
<link rel="stylesheet" href="../../css/main.min.6470f359d96cadb62114d84a859a08e047c933e85d36b945421da8260b62381977f4f70390c7eab26f30d96e167059bdd0e86e799c562d5d4eba32b5a9d4713c.css" integrity="sha512-ZHDzWdlsrbYhFNhKhZoI4EfJM&#43;hdNrlFQh2oJgtiOBl39PcDkMfqsm8w2W4WcFm90OhueZxWLV1OujK1qdRxPA==">


<noscript><link rel="stylesheet" href="../../css/noscript.min.e6f1ba19697eecfddfbf83ff7181b98181998f163d7005f6ae923451556bf85bef357f43dffe1522b92c1efab7fb38441f479e39b7a03e4313a8ef12b0b01f65.css" integrity="sha512-5vG6GWl&#43;7P3fv4P/cYG5gYGZjxY9cAX2rpI0UVVr&#43;FvvNX9D3/4VIrksHvq3&#43;zhEH0eeObegPkMTqO8SsLAfZQ=="></noscript>





    
    
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="(Un)biased Point Estimation">
  <meta name="twitter:description" content="This article explores how to estimate the maximum parameter $(\theta)$ of a uniform distribution from sample data, deriving the Maximum Likelihood Estimator (MLE), identifying its bias, and constructing an unbiased estimator by adjusting the MLE">
      <meta name="twitter:site" content="@ericpenax">

    <meta property="og:url" content="http://localhost:1313/posts/mle/">
  <meta property="og:site_name" content="Eric Peña">
  <meta property="og:title" content="(Un)biased Point Estimation">
  <meta property="og:description" content="This article explores how to estimate the maximum parameter $(\theta)$ of a uniform distribution from sample data, deriving the Maximum Likelihood Estimator (MLE), identifying its bias, and constructing an unbiased estimator by adjusting the MLE">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-11-12T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-11-12T00:00:00+00:00">
    <meta property="article:tag" content="Statistics">

    
	</head>
	<body class="landing is-preload">

		
			<div id="page-wrapper">

				
          <header id="header">
            <h1><a href="http://localhost:1313/">Eric Peña</a></h1>
						<nav id="nav">
							<ul>
								<li class="special">
                  <a href="#menu" class="menuToggle" aria-label='Menu'><span>Menu</span></a>
									<div id="menu">
										<ul>
				              
				              <li><a href="../../">Home</a></li>
				              
				              <li><a href="../../about/">About Me</a></li>
				              
				              <li><a href="../../posts/">Posts</a></li>
				              
										</ul>
									</div>
								</li>
							</ul>
						</nav>
					</header>

<article id="main">
  <header >
    <h2>(Un)biased Point Estimation</h2>
    
	</header>
	<section class="wrapper style5">
		<div class="inner">
      <h2 id="problem-setup">Problem Setup</h2>
<p>Suppose that $X$ has a uniform distribution on the interval $[0, \theta]$, where $\theta$ is unknown and $X$ could be reaction time to a stimulus or volumes of rocks, for example.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>


<div class="info-purple">
    <style>
      .info-purple a {
        color: inherit;
        color: #f39c12;
      }
      .info-purple a:hover {
        color: #f39c12;
        font-weight: bold;
      }
    </style>
    One goal could be to estimate $\theta$. That is, you have a random sample $(X_1, X_2, \ldots, X_n)$ from a uniform distribution on the interval $[0, \theta]$, where $\theta$ is the unknown parameter to be estimated.
</div>
<script>
document.querySelectorAll('.info-purple a').forEach(function(link) {
    link.setAttribute('target', '_blank');
    link.setAttribute('rel', 'noopener noreferrer');
});
</script>
<h3 id="likelihood-function">Likelihood Function</h3>
<p>The probability density function (PDF) of a single observation $X_i$ from a uniform distribution on $[0, \theta]$:
$$
f(x_i; \theta) =
\begin{cases}
\frac{1}{\theta} &amp; \text{if } 0 \leq x_i \leq \theta \\
0 &amp; \text{otherwise}
\end{cases}
$$
Given that the sample is independent and identically distributed (i.i.d.), the joint likelihood function for the entire sample is the product of the individual PDFs:</p>
<p>$$
L(\theta; X_1, X_2, \ldots, X_n) = \prod_{i=1}^{n} f(x_i; \theta) = \prod_{i=1}^{n} \frac{1}{\theta} \cdot \mathbf{1}_{{0 \leq x_i \leq \theta}}
$$</p>
<p>Here, $\mathbf{1}_{{0 \leq x_i \leq \theta}}$ is an indicator function that equals 1 if $(0 \leq x_i \leq \theta)$ for all $i$, and 0 otherwise. This simplifies to:</p>
<p>$$
L(\theta; X_1, X_2, \ldots, X_n) = \frac{1}{\theta^n} \cdot \mathbf{1}_{{\max(X_i) \leq \theta}}
$$</p>
<p>where $\max(X_1, X_2, \ldots, X_n)$ is the maximum of the observed sample values.</p>
<h3 id="finding-the-maximum-likelihood-estimator-mle">Finding the Maximum Likelihood Estimator (MLE)</h3>
<p>The MLE of $\theta$ is the value of $\theta$ that maximizes the likelihood function.</p>
<p>$$
L(\theta; X_1, X_2, \ldots, X_n) =
\begin{cases}
\frac{1}{\theta^n} &amp; \text{if } \theta \geq \max(X_i) \\
0 &amp; \text{if } \theta &lt; \max(X_i)
\end{cases}
$$</p>
<p>To maximize $L(\theta)$, we want the smallest possible value of $\theta$ that still satisfies the condition $\theta \geq \max(X_1, X_2, \ldots, X_n)$. Notice that since $L(\theta) = \frac{1}{\theta^n}$, $L(\theta)$ decreases as $\theta$ increases. The smallest possible $\theta$ (which maximizes the likelihood and where $L(\theta) &gt; 0$) is $\theta = \max(X_1, X_2, \ldots, X_n)$.</p>


<div class="info-blue">
    <style>
      .info-blue a {
        color: inherit;
        color: #f39c12;
      }
      .info-blue a:hover {
        color: #f39c12;
        font-weight: bold;
      }
    </style>
    Thus, the MLE for $\theta$ is:
$$
\hat{\theta} = \max(X_1, X_2, \ldots, X_n)
$$
</div>
<script>
  document.querySelectorAll('.info-blue a').forEach(function(link) {
    link.setAttribute('target', '_blank');
    link.setAttribute('rel', 'noopener noreferrer');
  });
</script>
<h3 id="biased-solution">Biased Solution</h3>
<p>For example, given a random sample of $n$ reaction times, $(X_1, X_2, \ldots, X_n)$, consider the estimator: $\hat\theta = \max(X_1, X_2, \ldots, X_n)$. This might seem like a reasonable choice but consider that this estimator will never overestimate $\theta$ since the largest value in the sample can never exceed the maximum of the distribution from which it came (i.e., $\theta$). Generally, in order for the estimator to be &ldquo;unbiased&rdquo;, some samples wil yield estimates that exceed $\theta$ and other samples will yield estimates smaller than $\theta$. Estimates that evenly hover around the true value is what we might expect from an unbiased estimator. A principal in statistics to keep in mind is the <em>Principal of Unbiased Estimation</em>.</p>


<div class="info-blue">
    <style>
      .info-blue a {
        color: inherit;
        color: #f39c12;
      }
      .info-blue a:hover {
        color: #f39c12;
        font-weight: bold;
      }
    </style>
    <!-- raw HTML omitted -->Principal of Unbiased Estimation<!-- raw HTML omitted --><!-- raw HTML omitted -->When choosing among several different estimators of $\theta$, select one that is unbiased.
</div>
<script>
  document.querySelectorAll('.info-blue a').forEach(function(link) {
    link.setAttribute('target', '_blank');
    link.setAttribute('rel', 'noopener noreferrer');
  });
</script>
<h3 id="calculating-bias-and-finding-unbiased-estimator">Calculating Bias and Finding Unbiased Estimator</h3>
<p>We already have evidence to claim that the MLE estimate $\left(\hat{\theta} = \max(X_1, X_2, \ldots, X_n)\right)$ is biased. Now we could ask how biased it is and whether there is hope in making the estimator unbiased. Put more formally, a point estimator $\hat\theta$ is said to be an unbiased estimator of $\theta$ is $\mathbb{E}[\hat\theta] = \theta$. Furthermore, the bias is the difference: $\mathbb{E}[\hat\theta] - \theta$. Of course, in order to find these expressions, we need to calculate the expected value of the estimor $\left(\hat{\theta} = \max(X_1, X_2, \ldots, X_n)\right)$. In order to do that, we first need to go through steps of calculating CDF and PDF of the MLE estimator.</p>
<hr>
<div class="centerb">
    
Step 1: CDF of the Maximum

</div>
<p>Let $Y = \hat{\theta} = \max(X_1, X_2, \ldots, X_n)$.</p>
<p>The cumulative distribution function (CDF) of $ Y $ is:
$$P(Y \leq y) = P(\max(X_1, X_2, \ldots, X_n) \leq y)$$
Since the $X_i$ are independent and uniformly distributed on $[0, \theta]$:
$$
P(Y \leq y) = P(X_1 \leq y) \cdot P(X_2 \leq y) \cdots P(X_n \leq y) = \left(\frac{y}{\theta}\right)^n
$$
for $ 0 \leq y \leq \theta $.</p>
<p>Thus, the CDF of $ Y $ is:
$$
F_Y(y) = \left(\frac{y}{\theta}\right)^n
$$
for $ 0 \leq y \leq \theta $.</p>
<hr>
<div class="centerb">
    
Step 2: PDF of the Maximum

</div>
<p>The probability density function (PDF) of $ Y $ can be found by differentiating the CDF:
$$
f_Y(y) = \frac{d}{dy} F_Y(y) = \frac{d}{dy} \left(\frac{y}{\theta}\right)^n = \frac{n}{\theta} \left(\frac{y}{\theta}\right)^{n-1}
$$
for $ 0 \leq y \leq \theta $.</p>
<hr>
<div class="centerb">
    
Step 3: Expectation of $Y$

</div>
<p>The expected value of $ Y $ is:
$$
\mathbb{E}[Y] = \int_0^{\theta} y \cdot f_Y(y) , dy = \int_0^{\theta} y \cdot \frac{n}{\theta} \left(\frac{y}{\theta}\right)^{n-1} dy
$$</p>
<p>This simplifies to:
$$
\mathbb{E}[Y] = \frac{n}{\theta^n} \int_0^{\theta} y^n , dy
$$
We can compute the integral:
$$
\int_0^{\theta} y^n , dy = \frac{y^{n+1}}{n+1} \Big|_0^{\theta} = \frac{\theta^{n+1}}{n+1}
$$
Thus:
$$
\mathbb{E}[Y] = \frac{n}{\theta^n} \cdot \frac{\theta^{n+1}}{n+1} = \frac{n \theta}{n+1}
$$</p>


<div class="info-blue">
    <style>
      .info-blue a {
        color: inherit;
        color: #f39c12;
      }
      .info-blue a:hover {
        color: #f39c12;
        font-weight: bold;
      }
    </style>
    So, the expected value of $\hat{\theta}$ is:
$$
\mathbb{E}[\hat{\theta}] = \frac{n}{n+1} \cdot \theta
$$
</div>
<script>
  document.querySelectorAll('.info-blue a').forEach(function(link) {
    link.setAttribute('target', '_blank');
    link.setAttribute('rel', 'noopener noreferrer');
  });
</script>
<hr>
<h3 id="conclusion">Conclusion</h3>
<p>The expectation result above reveals that $\frac{n}{n+1} &lt; 1$. This means that $\mathbb{E}[\hat{\theta}]$ is slightly less than $\theta$. This result indicates that the MLE, $\left(\hat{\theta} = \max(X_1, X_2, \ldots, X_n)\right)$, is a biased estimator for $\theta$, with the bias shrinking as the sample size $n$ gets large. The final task is to calculate the bias of the MLE estimator and find the unbiased estimator:</p>


<div class="info-green">
    <style>
      .info-green a {
        color: inherit;
        color: #f39c12;
      }
      .info-green a:hover {
        color: #f39c12;
        font-weight: bold;
      }
    </style>
    $$
\begin{align}
\text{bias} &amp;= \mathbb{E}[\hat\theta] - \theta \\
&amp;= \frac{n}{n+1} \cdot \theta - \theta \\
&amp;= -\frac{\theta}{n+1}
\end{align}
$$
</div>
<script>
document.querySelectorAll('.info-green a').forEach(function(link) {
    link.setAttribute('target', '_blank');
    link.setAttribute('rel', 'noopener noreferrer');
});
</script>
<p>$$
\text{since: } \mathbb{E}\left[ \frac{n+1}{n} \cdot \max(X_1, X_2, \ldots, X_n) \right] = \frac{n+1}{n} \cdot \mathbb{E}\left[\max(X_1, X_2, \ldots, X_n) \right] = \frac{n+1}{n} \cdot \frac{n}{n+1} \cdot \theta = \theta
$$</p>


<div class="info-green">
    <style>
      .info-green a {
        color: inherit;
        color: #f39c12;
      }
      .info-green a:hover {
        color: #f39c12;
        font-weight: bold;
      }
    </style>
    $$
\text{(unbiased estimator)}\ \ \ \ \hat{\theta}_u = \frac{n + 1}{n} \cdot \max(X_1, X_2, \ldots, X_n)
$$
</div>
<script>
document.querySelectorAll('.info-green a').forEach(function(link) {
    link.setAttribute('target', '_blank');
    link.setAttribute('rel', 'noopener noreferrer');
});
</script>
<p>This new estimator, $\hat{\theta}_u$, will overestimate and underestimate $\theta$ depending on the sample but will do so in an unbiased way.</p>
<h2 id="references">references</h2>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Devore, Jay L., Kenneth N. Berk, and Matthew A. Carlton. Modern mathematical statistics with applications. Vol. 285. New York: Springer, 2012.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>

		</div>
	</section>
</article>
				
					<footer id="footer">
						<ul class="icons">
              
              <li><a href="https://www.linkedin.com/in/eric-pena" class="icon brands fa-linkedin" target="_blank" rel="noopener noreferrer"><span class="label">LinkedIn</span></a></li>
              
              
              <li><a href="https://twitter.com/ericpenax" class="icon brands fa-twitter" target="_blank" rel="noopener noreferrer"><span class="label">Twitter</span></a></li>
              
              
              <li><a href="https://mstdn.science/@ericpena" class="icon brands fa-mastodon" target="_blank" rel="noopener noreferrer"><span class="label">Mastodon</span></a></li>
              
              
              <li><a href="https://github.com/ericpena" class="icon brands fa-github" target="_blank" rel="noopener noreferrer"><span class="label">GitHub</span></a></li>
              
              
              
              
              <li><a href="https://instagram.com/ericpena" class="icon brands fa-instagram" target="_blank" rel="noopener noreferrer"><span class="label">Instagram</span></a></li>
              
              
              
              <li><a href="mailto:eric.pena@binghamton.edu" class="icon solid fa-envelope" target="_blank" rel="noopener noreferrer"><span class="label">Email</span></a></li>
              
              

						</ul>
						<ul class="copyright">
              <li>&copy; 2025 Eric Peña</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
						</ul>
					</footer>

			</div>

      









<script src="../../js/bundle.min.935254271ae3006602cb92b38ba70062a462cefc8d3aa575338369d256bb8422a69fc18f64450e74b7e6c240b20a252f522f3b9f323294bdf9ed466f5fb28ee9.js" integrity="sha512-k1JUJxrjAGYCy5Kzi6cAYqRizvyNOqV1M4Np0la7hCKmn8GPZEUOdLfmwkCyCiUvUi87nzIylL357UZvX7KO6Q=="></script>


	</body>
</html>

