[{"authors":["admin"],"categories":null,"content":"Highly motivated professional with data modeling, engineering, and project management experience looking to gain the necessary education and training through a Master of System Science program at SUNY Binghamton to begin a career researching complex systems using computational and mathematical modeling.\n","date":1577830068,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1577830068,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Highly motivated professional with data modeling, engineering, and project management experience looking to gain the necessary education and training through a Master of System Science program at SUNY Binghamton to begin a career researching complex systems using computational and mathematical modeling.","tags":null,"title":"Eric Peña","type":"authors"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I'll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I'll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic's Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":["Eric Peña"],"categories":["Posts"],"content":"Introduction I had the pleasure of teaching physics for the Pre First-Year Academic and Career Engagement (PREFACE) Program. These are students that graduated high school and are transitioning into college to study engineering. The following is a problem I gave my students as a challenge question on their final. Many students found this problem interesting and we had a long discussion about the power of learning theoretical mechanics for the future of their respective degrees.\nThe Problem A ball is thrown at speed $v_o$ from zero height on level ground. At what angle $\\phi$ (from horizontal) should the ball be thrown such that the area under the trajectory is maximized? (Assume no air resistance)\nVisualize the Problem It's important to visualize the problem at hand. We can ask questions such as:\n How does the shape of trajectory change with different $\\phi$? How does the area under the curve change with changing $\\phi$?  Let's take a look at what this might look like.\n Figure 1 — Visualizing Trajectory of Ball  The Physics In order to find the area underneath a curve, we can use calculus. Generally, the area of an arbitrary curve in our x—y plane is:\n$$\\int_{x_o}^{x_f}y dx$$\nFor projectile motion, x and y are expressed as:\n$$x = x(t) = v_{o,x} t = v_o cos(\\phi) t$$\n$$y = y(t) = v_{o,y} t - \\frac{1}{2}g t^2 = v_o sin(\\phi) t - \\frac{1}{2} g t^2$$\nWe can use these expressions to integrate the curve in order to find the area. Note that x and y are both in terms of t, this is called parameterization because we're turning a multi-variable equation into an equation with one \u0026ldquo;parametric\u0026rdquo; parameter, t. Let's first talk about the integral bounds of the new integral that is now in terms of t:\nIt makes sense to allow time to start at zero: $$t_o = 0$$\nNow to find final time, let's find where the ball hits the ground again:\n$$v_o sin(\\phi) t - \\frac{1}{2} g t^2 = 0$$ $$t_{final} = \\frac{2 v_o sin(\\phi)}{g}$$\nTo find $dx$, we can take a time differential: $$dx = v_o cos(\\phi) dt$$\nPutting The Pieces Together To Find Area $$\\int_{0}^{\\frac{2 v_o sin(\\phi)}{g}} (v_o sin(\\phi) t - \\frac{1}{2} g t^2)(v_o cos(\\phi) dt)$$\nLet's think about how the area under the curve changes with changing $\\phi$. This will help us answer our first question (1).\n Figure 2 — Visualizing Trajectory of Ball With Changing $\\phi$  Solving this integral gives:\n$$\\frac{2 v^4 cos(\\phi) sin^3(\\phi)}{3g^2}$$\nPutting In Numbers To move forward with our analysis, let's put in some numbers.\nLet $v_o = 5 \\frac{m}{s}$ and $g = 10 \\frac{m}{s^2}$\nIn this case, the integral becomes:\n$$\\frac{25}{6}cos(\\phi) sin^3(\\phi)$$\nTo answer our second question (2) that asks how does the area under the curve change with changing $\\phi$, we can draw the plot below.\n Figure 3 — Visualizing Area Under Trajectory of Ball With Various Values of $\\phi$  The Answer To find the answer we take the derivative of the equation that tells us the area with respect to angle, set it equal to zero, then solve for $\\phi$.\n$$\\frac{d}{d\\phi}\\frac{25}{6}cos(\\phi) sin^3(\\phi) = 0$$\nWhich becomes:\n$$\\frac{25}{2} cos^2(\\phi) sin^2(\\phi) = \\frac{25 sin^4(\\phi)}{6}$$\nAfter some algebra, the answer becomes:\n$$\\phi = \\frac{\\pi}{3} = 1.0472$$\nAlthough the answer we are looking for is $\\frac{\\pi}{3}$, there are other non-intuitive, non-physical answers that technically satisfy our problem as well. For example, $\\frac{2\\pi}{3}$ is another answer. This would mean that we threw the ball behind us. $(-\\frac{2\\pi}{3})$ is another answer which would mean we threw the ball behind us and into the ground and gravity was reversed - this wouldn't make much physical sense. If we allowed the plot above to continue, we get a better picture of what is happening.\n Figure 4 — Visualizing Area Under Trajectory of Ball With Various Values of $\\phi$ for $0  Final Questions to Answers For completion, let's answer some basic questions about our ball given the initial conditions states above now that we know the optimal angle $\\phi$.\nHow long does it take the ball to land? $$t = \\frac{2 v_o sin(\\phi)}{g} = \\frac{\\sqrt3}{2} = 0.866025\\ s$$\nHow far does the ball go? $$x = v_o cos(\\phi) t = \\frac{5\\sqrt3}{4} = 2.16506\\ m$$\nHow high does the ball go? $$y = v_0 sin(\\phi) \\frac{t}{2} - \\frac{g}{2} \\left(\\frac{t}{2}\\right)^2 = \\frac{15}{16} = 0.9375\\ m$$\nWhat is the area under the curve that is maximized at $\\phi = \\frac{\\pi}{3}$? $$A = \\frac{25}{6} cos(\\phi) sin^3(\\phi) = \\frac{25 \\sqrt3}{32} = 1.35316\\ m^2$$\n Figure 5 — Ball Trajectory at Angle $\\frac{\\pi}{3}$  ","date":1577830068,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577830068,"objectID":"9cda84f6bfedc202810cf0dbe12d43fe","permalink":"/post/preface-program/","publishdate":"2019-12-31T17:07:48-05:00","relpermalink":"/post/preface-program/","section":"post","summary":"Teaching Physics in the Minority Engineering Program","tags":["Physics","Mathematics","Teaching"],"title":"Teaching Physics in the Minority Engineering Program –– Physics Example","type":"post"},{"authors":null,"categories":null,"content":" Figure 1 — Directed Network Which Represents Threshold Linear Network  Adjacency Matrix Representing Directed Network $$\\begin{pmatrix} 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\\\ 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0\\end{pmatrix}$$\n$$\\frac{d x_i}{dt} = -x_i + \\left[ \\sum_{j=1}^{n} W_{ij} x_j + \\theta \\right]_+ i = 1, \\ldots, n$$  Figure 2 — Solution Via Numerically Solving Differential Equation  Initial Conditions The initial conditions applied to the network above are the following:\n $x1[0] = .9$ $x2[0] = x3[0] = x4[0] = x5[0] = x6[0] = x7[0] = x8[0] = x9[0] = x10[0] = .5$   Figure 3 — Dynamics of Directed Network Which Represents Competitive Threshold Linear Network  \n","date":1576022400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576022400,"objectID":"5a1e5654860a972fec369af67935f90e","permalink":"/project/ctln-project/","publishdate":"2019-12-11T00:00:00Z","relpermalink":"/project/ctln-project/","section":"project","summary":"Diversity in Competitive Threshold Linear Networks","tags":["Networks","Research","Complex Systems","Programming","Mathematics","Modeling"],"title":"Diversity in Competitive Threshold Linear Networks","type":"project"},{"authors":null,"categories":null,"content":"Abstract The mechanism by which nature exhibits emergent patterns and behaviors has been a mystery throughout history. One application that has been developed which tends to mimic nature is Conway’s Game of Life — an application in the field of cellular automata. The ability to predict a final state of a system, given an initial state in the context of Game of Life, come as an insurmountable task. In this work, genetic algorithms are explored along with how they may be used to search for initial conditions such that their final outcomes are optimal. Optimal final states may be defined in terms of growth, diversity, and density of the cellular automaton evolution. This may be beneficial in exploring the way in which coupled components interact in mathematical and physical systems.\nMotivation Many will claim that the ultimate objective of science is to understand and model the natural world. There are many phenomena in nature whose patterns and behavior seem somewhat unpredictable yet these resulting patterns appear highly structured and organized. Scientists and mathematicians have developed techniques such as chaos theory and cellular automata for the attempt to model nature in its truest sense. In this paper we will take an approach to understand how structure stems from randomness in a cellular automata model. A cellular automaton is defined in terms of clear rules on each individual cell and its well defined neighborhood of cells that surround it. We will go into detail as to what this means in later chapters but let us begin by thinking about a two dimensional grid of cells that are all identical. We can even analogize this to a simple universe of people who are all the same and only know how to do the same task: become alive or die. Whether they become alive or die depends on the number of people around them who are either alive or dead given clear, unambiguous rules. Every person in this universe obeys the same universal laws—namely, in this context, the cellular automata rules. Given a clear and finite set of cellular automata rules and given a defined initial state, we can compute the state of a future grid—this will tell us which cells are alive and which are dead, after applying the rules onto the grid some predefined number n times. The defined cellular automata rules used in this report are those defined by Conway’s Game of Life. The well defined rules for Conway’s Game of Life will be explained in section 2.2.\n   Thesis Objective The objective of this project is to understand which initial conditions (initial states), given a set of welldefined cellular automata rules, produce the most optimized final states after n iterations of applying these rules. The variable being optimized is the fitness value where fitness is defined in terms of what I call growth, diversity, and density of the final state grids. These three terms and how they relate to this specific application are further explained in section 4.4. To make the objective clear, I will state it here and repeat it throughout the report to make sure we are on track with achieving it.\n OBJECTIVE: Given well-defined cellular automata rules defined by Conway’s Game of Life, determine an initial state that produces an optimal final state in terms of growth, diversity, and density after a finite number of iterations.\n Thesis Outline The report is organized in chapters that describe the major components of this project. The topics covered are the background of the application (Chapter 2), an overview of the genetic algorithms and how they are used to optimize initial states (Chapter 3), the details of the genetic algorithm implementation (Chapter 4), a description of the results (Chapter 5), and a few concluding thoughts and considerations for improvements and future work (Chapter 6).\nThe Report Click the icon below to read the full report. \n","date":1575158400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575158400,"objectID":"c82ae55cc29ddd6e7be2ff1e79f3b39b","permalink":"/project/liso-project/","publishdate":"2019-12-01T00:00:00Z","relpermalink":"/project/liso-project/","section":"project","summary":"Using genetic algorithm to optimize initial states","tags":["Genetic Algorithms","Complex Systems","Programming","Python","Modeling"],"title":"Genetic Algorithm — Cellular Automata Optimization","type":"project"},{"authors":null,"categories":null,"content":"Introduction I have separated my work into sections so ease of flow. All Python code is included in this article. Observations of the data are shown in the histogram and heatmap below.\n Header The header of my python file gives general information:\nTitle: Python Character Analysis Author: Eric Pena Date: Oct. 2019 Text Source: Academic Sample http://www.thegrammarlab.com/?nor-portfolio=1000000-word-sample-corpora   Packages Below are important packages that I am importing for the program to work properly.\nimport pandas as pd import fileinput as fi import matplotlib.pyplot as plt import seaborn as sns import string   User Defined Functions I have defined several functions used by the \\verb|main()| function:\ndef read(file): \u0026quot;\u0026quot;\u0026quot;Reads given file and parses characters Args: file: the text file to be parsed Returns: charArr: parsed character array \u0026quot;\u0026quot;\u0026quot; return [i for line in fi.input(file) for i in line] # ------------------------------------------------------------------- def count(array): \u0026quot;\u0026quot;\u0026quot;Counts characters and creates freq table Args: array: character array of text Returns: freq: dictionary that represents freq table \u0026quot;\u0026quot;\u0026quot; return {c: array.count(c) for c in array} # ------------------------------------------------------------------- def partition2(array): \u0026quot;\u0026quot;\u0026quot;Works similar to Mathematica's partition function but slightly differently. This function will create a string that combines each pair of characters in order to be hashed through by the count function. Args: array: this array Returns: \u0026quot;\u0026quot;\u0026quot; return [str(array[i]) + str(array[i + 1]) for i in range(len(array) - 1)] # ------------------------------------------------------------------- def dict_print(d): \u0026quot;\u0026quot;\u0026quot;Print function specifically for dictionary Args: d: dictionary Returns: None: only prints out the contents of the dictionary \u0026quot;\u0026quot;\u0026quot; [print(key[0] + ' --- ' + key[1] + ' :\\t' + str(val)) for key, val in d.items()] # ------------------------------------------------------------------- def to_dataframe(d): \u0026quot;\u0026quot;\u0026quot;converts the dictionary of transitions to a dataframe from which can be turned into a heatmap Args: d: dictionary Returns: df: dataframe \u0026quot;\u0026quot;\u0026quot; # :: Create dataframe df = pd.DataFrame(columns=('First', 'Second', 'Frequency')) # :: Initialize matrix alpha = list(string.ascii_letters)[:26] alpha.append(' ') for i in alpha: for j in alpha: df = df.append(pd.Series([i, j, 0], index=df.columns), ignore_index=True) # :: Pivot our dataframe to make a matrix for heatmap df = df.pivot(\u0026quot;First\u0026quot;, \u0026quot;Second\u0026quot;, \u0026quot;Frequency\u0026quot;) # :: Add relevant frequencies to the matrix for k in d: df[k[1]][k[0]] = d[k] df = df[df.columns].astype(int) return df # ------------------------------------------------------------------- def show_heatmap(df, filename): \u0026quot;\u0026quot;\u0026quot;Create and plot heatmap of data Args: df: dataframe of frequencies Returns: None: Instead will plot a heatmap of the data \u0026quot;\u0026quot;\u0026quot; # :: Creae heatmap and customize sns.set() ax = sns.heatmap(df, cmap=\u0026quot;binary\u0026quot;, robust=True, xticklabels=True, yticklabels=True) ax.xaxis.set_label_position('top') ax.xaxis.set_ticks_position('top') ax.spines['top'].set_visible(False) ax.tick_params(top=False, left=False) ax.xaxis.label.set_color('darkgray') ax.yaxis.label.set_color('darkgray') ax.tick_params(axis='x', colors='darkgray') ax.tick_params(axis='y', colors='darkgray') plt.xlabel('Second Letter', fontsize=18) plt.ylabel('First Letter', fontsize=18) plt.show() figure = ax.get_figure() figure.savefig(filename, dpi=400)   Main Program This shows the code for the main program which utilizes the functions above.\ndef main(): # ---------------------------MAIN PROGRAM--------------------------- # :: Reads in text file # :: Counts the frequencies # :: Data stored in dictionary # :: Plots histogram of results freq_dict = count(read('text.txt')) plt.bar(freq_dict.keys(), freq_dict.values(), color='gray') plt.title('Character Histogram') plt.xlabel('Characters') plt.ylabel('Frequency') plt.show() # :: Reads in text file # :: Partitions in 2-tuples for transitions # :: Data stored in dictionary # :: Frequencies are printed to console/terminal dict_print(count(partition2(read('text.txt')))) df = to_dataframe(count(partition2(read('text.txt')))) print(df) filename = '/Users/ericpena/iCloud/Binghamton_Courses/500_Computational_Tools/HW2/heatmap.png' show_heatmap(df, filename) if __name__ == '__main__': main()  Plot of Histogram  Figure 1 — Histogram that shows frequencies of characters appearing in the text  Histogram Observations Here are a few observations about the histogram above:\n $space\\ character$: The space character is by far the most frequent. This makes sense since after each word, a space appears ${j, z, x, k}$: Characters such as $j$, $z$, $x$, and $k$ are low frequency \u0026mdash; not often present in common words $vowels$: It makes sense for the frequency of the vowels to be higher than consonants given how English is structured  Heatmap of Character Transitions The heat map below visually represents the frequencies of the transitions $c_i \\rightarrow c_{i+1}$ where $c_i$ is the $i^{th}$ character in the supplied text file.\n Figure 2 — Heatmap that shows the frequencies of character transitions  Heatmap Observations Here are a few observations about the heatmap above:\n $Common\\ Occurences$: Some common occurrences: $t \\rightarrow h$, $i \\rightarrow n$, $n \\rightarrow t$, $r \\rightarrow e$, $t \\rightarrow i$ $Spaces$: As expected the row and column of the $space$ is quite active \u0026mdash; this makes sense since all words start and end with a $space$ $Bare$: It's interesting but not unexpected that the right bottom right is quite bare \u0026mdash; very low frequencies later in the alphabet  Robustness Parameter The heatmap above is actually using a robust=True parameter that normalizes the frequencies into a small range in order to improve the visualization. This is an improvement over the heatmap with the original frequencies. See below for the difference between the $RAW$ heatmap and the $ROBUST$ heatmap. More visual information can be obtained by using the $robust$ parameter since the `interesting\u0026rsquo; events are much more pronounced.\n Figure 3 — Shows the difference between the Raw and Robust frequencies for the heatmap  Appendix — Output Data  Histogram Frenquencies {\u0026lsquo;d\u0026rsquo;: 234, \u0026lsquo;i\u0026rsquo;: 574, \u0026lsquo;f\u0026rsquo;: 233, \u0026lsquo;e\u0026rsquo;: 958, \u0026lsquo;r\u0026rsquo;: 428, \u0026lsquo;n\u0026rsquo;: 492, \u0026lsquo;c\u0026rsquo;: 255, ' \u0026lsquo;: 1370, \u0026lsquo;w\u0026rsquo;: 111, \u0026lsquo;h\u0026rsquo;: 344, \u0026lsquo;m\u0026rsquo;: 184, \u0026lsquo;s\u0026rsquo;: 455, \u0026lsquo;t\u0026rsquo;: 653, \u0026lsquo;o\u0026rsquo;: 475, \u0026lsquo;u\u0026rsquo;: 206, \u0026lsquo;a\u0026rsquo;: 561, \u0026lsquo;p\u0026rsquo;: 146, \u0026lsquo;l\u0026rsquo;: 336, \u0026lsquo;y\u0026rsquo;: 77, \u0026lsquo;x\u0026rsquo;: 24, \u0026lsquo;b\u0026rsquo;: 111, \u0026lsquo;k\u0026rsquo;: 15, \u0026lsquo;g\u0026rsquo;: 103, \u0026lsquo;v\u0026rsquo;: 60, \u0026lsquo;q\u0026rsquo;: 20, \u0026lsquo;j\u0026rsquo;: 9, \u0026lsquo;z\u0026rsquo;: 11}\nHeatmap Frenquencies d \u0026mdash; i :\t30 i \u0026mdash; f :\t11 f \u0026mdash; f :\t15 f \u0026mdash; e :\t10 e \u0026mdash; r :\t114 r \u0026mdash; e :\t113 e \u0026mdash; n :\t105 n \u0026mdash; c :\t22 c \u0026mdash; e :\t49 e \u0026mdash; :\t339 \u0026mdash; w :\t79 w \u0026mdash; h :\t23 h \u0026mdash; e :\t210 \u0026mdash; m :\t53 m \u0026mdash; c :\t1 c \u0026mdash; :\t8 \u0026mdash; i :\t72 i \u0026mdash; s :\t61 s \u0026mdash; :\t199 \u0026mdash; t :\t252 t \u0026mdash; h :\t212 m \u0026mdash; o :\t13 o \u0026mdash; i :\t5 s \u0026mdash; t :\t41 t \u0026mdash; u :\t11 u \u0026mdash; r :\t46 \u0026mdash; c :\t90 c \u0026mdash; o :\t54 o \u0026mdash; n :\t104 n \u0026mdash; t :\t88 t \u0026mdash; e :\t94 t \u0026mdash; :\t107 m \u0026mdash; a :\t18 a \u0026mdash; :\t40 a \u0026mdash; s :\t55 s \u0026mdash; s :\t18 \u0026mdash; o :\t93 o \u0026mdash; f :\t70 f \u0026mdash; :\t73 \u0026mdash; s :\t69 s \u0026mdash; a :\t14 a \u0026mdash; m :\t23 m \u0026mdash; p :\t25 p \u0026mdash; l :\t14 l \u0026mdash; e :\t47 \u0026mdash; a :\t168 a \u0026mdash; f :\t6 f \u0026mdash; t :\t4 r \u0026mdash; :\t64 \u0026mdash; h :\t40 h \u0026mdash; u :\t12 u \u0026mdash; m :\t9 m \u0026mdash; i :\t37 i \u0026mdash; d :\t28 i \u0026mdash; t :\t46 t \u0026mdash; y :\t11 y \u0026mdash; :\t60 \u0026mdash; e :\t40 e \u0026mdash; x :\t11 x \u0026mdash; p :\t3 p \u0026mdash; o :\t41 o \u0026mdash; s :\t28 s \u0026mdash; u :\t28 a \u0026mdash; n :\t92 n \u0026mdash; d :\t65 d \u0026mdash; :\t140 m \u0026mdash; d :\t1 \u0026mdash; d :\t39 d \u0026mdash; r :\t2 r \u0026mdash; y :\t12 \u0026mdash; r :\t37 e \u0026mdash; s :\t71 u \u0026mdash; l :\t21 l \u0026mdash; t :\t4 t \u0026mdash; s :\t17 s \u0026mdash; c :\t3 c \u0026mdash; u :\t3 u \u0026mdash; s :\t31 s \u0026mdash; i :\t53 i \u0026mdash; o :\t60 n \u0026mdash; :\t131 c \u0026mdash; h :\t34 e \u0026mdash; m :\t26 i \u0026mdash; c :\t47 c \u0026mdash; a :\t45 a \u0026mdash; l :\t81 l \u0026mdash; :\t50 o \u0026mdash; m :\t24 t \u0026mdash; i :\t92 \u0026mdash; f :\t103 f \u0026mdash; i :\t59 i \u0026mdash; b :\t38 b \u0026mdash; e :\t59 r \u0026mdash; s :\t37 w \u0026mdash; e :\t33 e \u0026mdash; l :\t40 l \u0026mdash; l :\t49 \u0026mdash; k :\t1 k \u0026mdash; n :\t1 n \u0026mdash; o :\t21 o \u0026mdash; w :\t12 w \u0026mdash; n :\t3 h \u0026mdash; a :\t34 a \u0026mdash; t :\t55 \u0026mdash; l :\t37 l \u0026mdash; i :\t42 i \u0026mdash; g :\t23 g \u0026mdash; n :\t4 o \u0026mdash; c :\t10 l \u0026mdash; u :\t30 l \u0026mdash; o :\t18 i \u0026mdash; n :\t128 n \u0026mdash; v :\t2 v \u0026mdash; e :\t34 g \u0026mdash; a :\t8 e \u0026mdash; d :\t68 o \u0026mdash; u :\t27 u \u0026mdash; n :\t17 n \u0026mdash; e :\t37 \u0026mdash; q :\t2 q \u0026mdash; u :\t20 u \u0026mdash; a :\t8 i \u0026mdash; e :\t24 d \u0026mdash; o :\t5 o \u0026mdash; e :\t2 \u0026mdash; n :\t19 o \u0026mdash; t :\t30 a \u0026mdash; d :\t10 d \u0026mdash; d :\t1 \u0026mdash; u :\t12 u \u0026mdash; p :\t9 p \u0026mdash; :\t6 t \u0026mdash; o :\t47 o \u0026mdash; :\t48 i \u0026mdash; m :\t21 l \u0026mdash; y :\t27 \u0026mdash; b :\t46 e \u0026mdash; c :\t25 a \u0026mdash; u :\t9 s \u0026mdash; e :\t44 n \u0026mdash; l :\t4 a \u0026mdash; j :\t1 j \u0026mdash; o :\t1 o \u0026mdash; r :\t66 a \u0026mdash; r :\t64 e \u0026mdash; p :\t6 r \u0026mdash; t :\t15 d \u0026mdash; e :\t24 e \u0026mdash; t :\t32 r \u0026mdash; m :\t17 \u0026mdash; p :\t66 p \u0026mdash; e :\t20 c \u0026mdash; t :\t35 p \u0026mdash; r :\t27 r \u0026mdash; o :\t42 e \u0026mdash; i :\t11 n \u0026mdash; s :\t24 x \u0026mdash; t :\t4 t \u0026mdash; r :\t17 r \u0026mdash; a :\t32 a \u0026mdash; c :\t43 t \u0026mdash; a :\t24 a \u0026mdash; b :\t18 b \u0026mdash; l :\t12 r \u0026mdash; g :\t6 n \u0026mdash; i :\t28 t \u0026mdash; t :\t15 u \u0026mdash; c :\t7 h \u0026mdash; :\t31 w \u0026mdash; a :\t19 a \u0026mdash; x :\t12 x \u0026mdash; e :\t2 f \u0026mdash; a :\t20 l \u0026mdash; c :\t1 o \u0026mdash; h :\t1 h \u0026mdash; o :\t18 o \u0026mdash; l :\t26 l \u0026mdash; s :\t11 c \u0026mdash; i :\t8 d \u0026mdash; s :\t16 i \u0026mdash; l :\t28 l \u0026mdash; a :\t44 r \u0026mdash; l :\t5 e \u0026mdash; q :\t7 u \u0026mdash; e :\t20 a \u0026mdash; p :\t11 p \u0026mdash; p :\t4 o \u0026mdash; x :\t1 x \u0026mdash; :\t9 w \u0026mdash; t :\t3 h \u0026mdash; i :\t26 \u0026mdash; g :\t19 g \u0026mdash; o :\t2 o \u0026mdash; o :\t2 o \u0026mdash; d :\t2 a \u0026mdash; g :\t7 g \u0026mdash; r :\t16 e \u0026mdash; e :\t18 m \u0026mdash; e :\t46 \u0026mdash; v :\t22 v \u0026mdash; a :\t20 b \u0026mdash; y :\t10 e \u0026mdash; z :\t2 z \u0026mdash; :\t2 n \u0026mdash; z :\t1 z \u0026mdash; a :\t1 f \u0026mdash; l :\t8 a \u0026mdash; v :\t12 g \u0026mdash; h :\t10 b \u0026mdash; a :\t11 r \u0026mdash; n :\t11 n \u0026mdash; h :\t6 s \u0026mdash; k :\t6 k \u0026mdash; :\t7 e \u0026mdash; a :\t39 r \u0026mdash; c :\t2 g \u0026mdash; e :\t13 u \u0026mdash; g :\t5 g \u0026mdash; u :\t10 u \u0026mdash; i :\t13 e \u0026mdash; y :\t5 n \u0026mdash; g :\t33 g \u0026mdash; :\t29 f \u0026mdash; r :\t9 m \u0026mdash; :\t19 r \u0026mdash; i :\t36 e \u0026mdash; o :\t6 o \u0026mdash; g :\t3 p \u0026mdash; h :\t4 e \u0026mdash; g :\t6 g \u0026mdash; i :\t7 o \u0026mdash; p :\t10 r \u0026mdash; f :\t13 s \u0026mdash; h :\t13 w \u0026mdash; s :\t3 h \u0026mdash; t :\t7 a \u0026mdash; i :\t13 w \u0026mdash; i :\t15 s \u0026mdash; w :\t3 x \u0026mdash; i :\t4 m \u0026mdash; u :\t7 d \u0026mdash; u :\t7 i \u0026mdash; q :\t9 p \u0026mdash; i :\t7 i \u0026mdash; i :\t1 i \u0026mdash; :\t1 e \u0026mdash; f :\t7 p \u0026mdash; a :\t9 c \u0026mdash; k :\t3 k \u0026mdash; e :\t5 e \u0026mdash; v :\t10 f \u0026mdash; u :\t9 b \u0026mdash; s :\t1 s \u0026mdash; o :\t13 r \u0026mdash; p :\t4 p \u0026mdash; t :\t6 m \u0026mdash; n :\t8 f \u0026mdash; o :\t26 n \u0026mdash; f :\t6 d \u0026mdash; a :\t3 i \u0026mdash; a :\t23 h \u0026mdash; l :\t1 i \u0026mdash; k :\t3 n \u0026mdash; y :\t1 n \u0026mdash; a :\t19 r \u0026mdash; v :\t1 l \u0026mdash; w :\t1 a \u0026mdash; y :\t3 y \u0026mdash; s :\t2 v \u0026mdash; i :\t5 r \u0026mdash; r :\t8 s \u0026mdash; p :\t5 i \u0026mdash; z :\t3 z \u0026mdash; e :\t4 o \u0026mdash; b :\t1 b \u0026mdash; t :\t1 i \u0026mdash; p :\t1 y \u0026mdash; i :\t2 i \u0026mdash; v :\t10 c \u0026mdash; r :\t9 c \u0026mdash; c :\t2 g \u0026mdash; y :\t1 \u0026mdash; z :\t3 z \u0026mdash; i :\t4 s \u0026mdash; m :\t7 c \u0026mdash; l :\t4 p \u0026mdash; u :\t4 t \u0026mdash; w :\t6 m \u0026mdash; s :\t5 b \u0026mdash; o :\t5 l \u0026mdash; d :\t11 b \u0026mdash; i :\t4 p \u0026mdash; s :\t4 b \u0026mdash; u :\t7 u \u0026mdash; t :\t12 h \u0026mdash; y :\t2 y \u0026mdash; d :\t1 i \u0026mdash; r :\t8 c \u0026mdash; y :\t1 g \u0026mdash; g :\t1 a \u0026mdash; z :\t1 n \u0026mdash; k :\t1 y \u0026mdash; z :\t1 l \u0026mdash; m :\t1 \u0026mdash; y :\t3 y \u0026mdash; p :\t2 x \u0026mdash; c :\t2 r \u0026mdash; u :\t4 u \u0026mdash; f :\t1 d \u0026mdash; l :\t1 o \u0026mdash; a :\t1 s \u0026mdash; y :\t1 y \u0026mdash; m :\t1 o \u0026mdash; v :\t1 d \u0026mdash; v :\t2 u \u0026mdash; :\t1 \u0026mdash; j :\t5 j \u0026mdash; u :\t2 y \u0026mdash; t :\t3 a \u0026mdash; q :\t1 y \u0026mdash; r :\t1 g \u0026mdash; l :\t1 w \u0026mdash; o :\t6 r \u0026mdash; d :\t5 u \u0026mdash; d :\t2 u \u0026mdash; b :\t3 y \u0026mdash; e :\t4 u \u0026mdash; o :\t1 m \u0026mdash; m :\t1 e \u0026mdash; w :\t6 w \u0026mdash; :\t5 s \u0026mdash; b :\t1 g \u0026mdash; f :\t1 m \u0026mdash; b :\t3 a \u0026mdash; w :\t1 a \u0026mdash; k :\t1 b \u0026mdash; :\t1 n \u0026mdash; u :\t2 k \u0026mdash; s :\t2 n \u0026mdash; j :\t1 j \u0026mdash; a :\t1 s \u0026mdash; r :\t1 a \u0026mdash; e :\t1 j \u0026mdash; e :\t5 a \u0026mdash; h :\t1 r \u0026mdash; b :\t1 o \u0026mdash; j :\t1 e \u0026mdash; u :\t2 v \u0026mdash; o :\t1 s \u0026mdash; l :\t4 h \u0026mdash; m :\t1 h \u0026mdash; r :\t2 d \u0026mdash; w :\t3 w \u0026mdash; r :\t1 e \u0026mdash; j :\t1 s \u0026mdash; q :\t1\n","date":1570060800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570060800,"objectID":"4ecdf99e91b41cf1d9fe310dacbd8c8e","permalink":"/project/heatmap-project/","publishdate":"2019-10-03T00:00:00Z","relpermalink":"/project/heatmap-project/","section":"project","summary":"Creating Histogram and Heatmap of Character Frequency in Python","tags":["Modeling","Programming","Python"],"title":"Python Character Analysis","type":"project"},{"authors":["Eric Peña"],"categories":["Posts"],"content":"Components of a Genetic Algorithm Genetic Algorithm Written in Python from fuzzywuzzy import fuzz import random import string class Agent: def __init__(self, length): # Initialize a new agent self.string = ''.join(random.choice(string.ascii_letters) for _ in range(length)) self.fitness = -1 def __str__(self): return 'String: ' + str(self.string) + ' Fitness: ' + str(self.fitness) in_str = None in_str_len = None population = 20 generations = 5000 # All the code to evolve def ga(): agents = init_agents(population, in_str_len) for generation in range(generations): print('Generation: ' + str(generation)) agents = fitness(agents) agents = selection(agents) agents = crossover(agents) agents = mutation(agents) if any(agent.fitness \u0026gt;= 90 for agent in agents): print('Threshold met!') exit(0) def init_agents(population, length): return [Agent(length) for _ in range(population)] def fitness(agents): for agent in agents: agent.fitness = fuzz.ratio(agent.string, in_str) return agents def selection(agents): agents = sorted(agents, key=lambda agent: agent.fitness, reverse=True) print('\\n'.join(map(str, agents))) agents = agents[:int(0.2 * len(agents))] return agents def crossover(agents): offspring = [] for _ in range(int((population - len(agents)) / 2)): parent1 = random.choice(agents) parent2 = random.choice(agents) child1 = Agent(in_str_len) child2 = Agent(in_str_len) split = random.randint(0, in_str_len) child1.string = parent1.string[0:split] + parent2.string[split:in_str_len] child2.string = parent2.string[0:split] + parent1.string[split:in_str_len] offspring.append(child1) offspring.append(child2) agents.extend(offspring) return agents def mutation(agents): for agent in agents: for idx, param in enumerate(agent.string): if random.uniform(0.0, 1.0) \u0026lt;= 0.1: agent.string = agent.string[0:idx] + \\ random.choice(string.ascii_letters) + \\ agent.string[idx + 1:in_str_len] return agents if __name__ == '__main__': in_str = 'ericpena' in_str_len = len(in_str) ga()  Results ","date":1567987200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567987200,"objectID":"1ac8ad2deaf6f3be3b591a2607b988e6","permalink":"/post/ga-intro/","publishdate":"2019-09-09T00:00:00Z","relpermalink":"/post/ga-intro/","section":"post","summary":"Introduction to Genetic Algorithms — Program that finds optimal text value","tags":["Genetic Algorithms","Complex Systems","Programming","Python","Simulation"],"title":"First Genetic Algorithm","type":"post"},{"authors":["Eric Peña"],"categories":["Posts"],"content":"  Creating fib(n) function fib(n) if (n == 1 || n == 2) return 1 else return fib(n - 1) + fib(n - 2) end end  Timing fib(n) 1:40 function fibTime(k) t = [] for i in 1:k push!(t, (@timed fib(i))[2]) end return t end # :: Print @timed Fibonacci 1 through 40 println(fibTime(40))  Plotting @Timed Results The timing for Julia is surprisingly very fast!\nusing Plots plot(fibTime(40), title=\u0026quot;Timed Recursive Fibonacci Algorithm\u0026quot;, color = :red, fill = (0, .3, :red), legend = false) xaxis!(\u0026quot;[n given in fib(n)]\u0026quot;) yaxis!(\u0026quot;Time [seconds]\u0026quot;)    Figure 1 — Timed Recursive Algorithm That Calculates $n^{th}$ Fibonacci Number in Julia  Achieve Results in Python from matplotlib import pyplot as plt import time def fib(n): if (n == 1) or (n == 2): return 1 else: return fib(n - 1) + fib(n - 2) def fibTimed(k): t = [] for i in range(1, k + 1): s = time.time() fib(i) fib_t = time.time() - s t.append(fib_t) return t result = fibTimed(40) print(result) plt.plot(result) plt.title(\u0026quot;Python @Timed Recursive fib(n) Algorithm\u0026quot;) plt.xlabel(\u0026quot;[n given in fin(n)]\u0026quot;) plt.ylabel(\u0026quot;Time [seconds]\u0026quot;) plt.show()   The results from Python are significantly slower than compared to Julia. $Fib(40)$ takes nearly $30$ seconds to complete.\n Figure 2 — Timed Recursive Algorithm That Calculates $n^{th}$ Fibonacci Number in Python  Show Julia Versus Python Comparison The plot below shows that Julia is significantly more efficient compared to Python for this recursive algorithm.\n  Figure 3 — Timed Recursive Algorithm Between Julia and Python between $n = 30$ and $n = 40$ ","date":1567987200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567987200,"objectID":"457b2401468a0a853e4e0cc203f5b527","permalink":"/post/julia/","publishdate":"2019-09-09T00:00:00Z","relpermalink":"/post/julia/","section":"post","summary":"Compare the computational speed of Julia compared to Python supporting how fast Julia can be","tags":["Programming","Python","Julia"],"title":"Speed of Julia","type":"post"},{"authors":["Eric Peña"],"categories":["Posts"],"content":"Part I: Providing the multifaceted story of how complex systems has evolved into what it is today is no easy feat. Dr. Melanie Mitchell not only gives a comprehensive historical tour of science and mathematics, she also provides foundational knowledge that any reader can carry to appreciate the essence of what it means for a system to be complex in the technical sense. Early on, she gives a clear definition of complex systems as an interdisciplinary field that studies how large networks of entities with no central controller can organize themselves and exhibit collective behavior given simple rules. However, she also humbly confesses that given how nebulous the field is, there has yet to be one clear definition of complexity that everyone can agree on. I appreciate how candid she is about what is known and what is not known in this field. Mitchell shares that even a panel she organized of great system science thinkers at the Santa Fe Institute could not agree on an answer to the question: \u0026ldquo;how do you define complexity?\u0026quot;.\nShe acknowledges the potential skepticism that one might feel because of the nascence of this field. However, she encourages the reader by sharing fascinating real-world examples\u0026mdash;such as ant colonies, brain activity, and internet networks\u0026mdash;that show the ubiquity of complex systems and its necessity in understanding how systems evolve in our lives. She eloquently describes the emergent collective behavior that arises from these systems and the wide scale at which they occur. From thoughts and consciousness in the brain to global economic market movements, these can all be thought of as emergent phenomena attributed to complexity. She mentions that some have even call these systems superorganisms that exhibit a collective intelligence even in non-living, non-conscious systems. She borrows examples from economics stating that the self-interest of smaller economic entities such as companies and individuals create macroscopic effects that tend to not resemble the smaller systems at all. I appreciate that complex systems are not only accessible to all of us everywhere we are, but also require them to survive such as brain neuroactivity and heartbeat rhythms.\nGiven my background, the section on dynamics, chaos, and prediction resonated with me most. Mitchell beautifully tells the story of how the natural world was analyzed by great scientists in history and how our understanding of nature evolved. This historical account builds from Aristotle, Copernicus, Galileo, Kepler, and finally Isaac Newton and his revolutionary laws of motion. Newton established a concept of universality extending the natural laws from the terrestrial realm to celestial bodies\u0026mdash;one of the most enlightening realizations in science.\nWhen I consider physics paradigms in the context of complexity, I think about the dismantling of reductionism\u0026mdash;where the notion that a system is the sum of its parts, as is the case in classical mechanics\u0026mdash;is no longer valid. Mitchell does not talk much about reductionism directly but instead touches on a topic much richer on how concepts in physics directly led to the understanding of complexity and its causes. Much of physics is used primary to make predictions but Mitchell mentions two important scientific discoveries that make prediction very difficult: the uncertainty principle from quantum mechanics and the sensitivity of initial conditions from chaos theory. In 1927, Heisenberg taught us that the momentum and position of a particle cannot be known simultaneously but rather act as a trade-off of information. This is not an experimental limitation but an inherent limitation of information that is written into the law of physics. This must have been devastating during the time of Newton's \u0026ldquo;clockwork universe\u0026rdquo; when mathematicians such as Pierre Simon Laplace had ideas of being able to, in theory, predict everything at all times given we have the information to do so. The development of chaos theory by Poincar'e and Lorenz had a similar effect stating that even the tiniest variation in initial conditions can lead to drastically different outcomes\u0026mdash;which served as another blow to predictability.\nMitchell sheds hope and motivates the reader by mentioning that in the same way there are universal laws in physics, there are similar invariants in the study of complex systems as well. Period-doubling as a system evolves to a chaotic state and the Feigenbaum's constant for the rate at which bifurcations converge are examples of remarkable invariant properties in complex systems. This provides an indication that the essence of physics can likely be applied to the field of complex systems and even possibly toward its version of a unified theory.\nDr. Melanie Mitchell seamlessly weaves together the concepts of information, entropy, energy, and thermodynamics. These are integral to the field so much so that she even refers to \u0026ldquo;entropy-defying self-organization\u0026rdquo; as the \u0026ldquo;holy grail of complex systems\u0026rdquo;. She resolves the misconception that entropy can at times decrease without consequence even though the law of thermodynamics forbids it. She talks about this in terms of Maxwell's Demon stating that work is required for the demon to do its job. I had learned about Maxwell's Demon in the past but had never considered this in terms of information. Szilard thought that work and energy was expended when obtaining the measurements of the particle's velocities\u0026mdash;in other words, it requires work to obtain the relevant information needed. I find this to be a novel idea and a clever way to connect all of these concepts in one easy to understand example.\nAnother pivotal moment for me in reading Part I was in chapter 4\u0026mdash;computation. In the same way that physics endured a disillusionment of endless predictability, mathematics and computability had a relatable event in history through the work of Kurt Gödel and Alan Turing. David Hilbert's provocative questions for the mathematics community challenged the stability of mathematics itself. Gödel figured out how to convert statements into mathematical language and learned that there exists self-contradictory mathematical statements\u0026mdash;showing that not everything in mathematics could be proven. Mathematics was viewed as being exacting and able to prove anything at that time. Gödel's Incompleteness Theorem shattered the apparent grandeur of mathematics and worried many practitioners. Alan Turing also came up with a similar answer using what was called a Turing Machine. The result had extended to machine language as well.\nDr. Mitchell is not only able to clearly explain a topic as abstruse as complex theory, she does so to a general audience without inundating the reader with technical jargon. Since there is not a definition of complexity that the scientific community can agree on, Mitchell offers some thoughts about possible ways that complexity could be defined. She is again very candid about the limitations of these definitions and explains why they would not hold up in isolation. All throughout Part I, she keeps the theme of being informative, honest, and motivating. She is honest about scientists not yet having a clear understanding of the field but also offers other examples in history where this was also true such as the concept of energy before it was well understood. Even today, research on genes and dark matter have yet to be understood fully but are making tremendous progress. I learned a great deal so far from this book and I look forward to the insight it has to offer in the remaining chapters.\nParts II and III Melanie Mitchell states that it is hypothesized that the balance between exploration and exploitation of information may serve as a general property of what are now called complex systems. Having read parts II and III of the book, it is evident that this idea could not have been developed without the use of computation, particularly self-replicating systems. Mitchell takes us deeper into the journey of complex systems and focuses on the connection between computation and living systems. From the fine details of a genetic algorithm to large-scope philosophical ideas, she provides different levels of abstraction allowing the reader to appreciate these topics from all angles. The historical account she gives of evolutionary computation reads as if she is alluding to the past and the future almost simultaneously \u0026mdash; she tells where the inspiration has come from and where it could lead.\nSelf Replication Part II begins with the idea of what life is and what are its properties. Mitchell explains how the idea of self-replicating artificial life is an old idea but continues to live on, even in our movies and artwork today. I thought this was a great introduction to the idea of evolutionary programming. The discussion leads to the idea of reproduction of computer systems that can, for example, print their own code. This is a novel idea on a fundamental level and a great zeroeth-order example to begin understanding its significance; but the fact that DNA, for example, can actually transcribe its own interpreter may provoke one to admit: some systems actually are living.\nGenetic Algorithms I was inspired by the chapter on genetic algorithms to create my own program\u0026mdash;a simple program that evolves and learns to print the characters: ericpena. Although a simple task for a computer to perform, it made apparent the power of this methodology to solve more complicated tasks. John von Neumann is essentially the person who established the idea of self-replicating machines in a tangible way. Although, he thought that replication was not enough as these systems also need to evolve, learn, and compete with one another to survive. It was John Holland that proposed the idea for genetic algorithms that was inspired by how nature evolves to find near-optimal solutions via natural selection. Mitchell gives a great example on how a genetic algorithm can help improve the performance of Robby, the Soda-Can-Collecting Robot. This chapter revealed the vast potential for genetic algorithms and how in many ways they are better than human-developed algorithms for various tasks. One particular discussion that stood out to me regarding Robby is the following: Robby's success isn't necessarily dependent on the individual, step-by-step decisions that Robby makes to collect cans but rather the aggregate of these steps that define a hollistic strategy, a rather successful strategy at that. Mitchell explains this by stating that it isn't always individual genes at work but rather their interactions that produce results.\nCellular Automata and The Nature of Computability I have been enthralled by cellular automata ever since I first learned about them. In this chapter, Mitchell talks about how computation occurs in nature and what it even means for nature to \u0026ldquo;compute\u0026rdquo;. Similar to the way in which physicists simplify problems to gain understanding\u0026mdash;through frictionless slopes and spherical cows\u0026mdash;scientists have performed a simplification for computation in the form of cellular automata. Although the rules of a cell can be relatively simple, the interconnectedness of a grid of cells can produce complex behavior that can, at times, simulate natural processes such as forest fires, fire flies, and even neurons. The field of cellular automata seemed to have taken a life of its own. John von Neumann, who played a key role in creating cellular automata, proved that it is actually Turing Complete. John Conway's Game of Life programs popularize the discipline even further especially when proving that his game is capable of simulating a universal computer. With the large number of configurations and possibilities, it may have been difficult to wrap one's head around the innate behavior of this mechanism. It was Stephan Wolfram, who nothing short of genius, worked diligently and cleverly to classify the ways in which cellular automata can behave and what patterns it can exhibit. He created libraries of patterns for these things, particularly four classes, and became rather popular for his book on them, {\\it A New Kind of Science}. I learned about Wolfram during my undergraduate program and used Mathematica for many of my homework problems\u0026mdash;although I had not read about his beliefs that Mitchell mentions in the reading. I found it interesting that Wolfram believes natural processes are intrinsically computable and can be explained in this way. While in physics, I conceded to the idea that nature is infinitely complex and our best hope in grasping it is to make very accurate approximations with efforts such as quantum mechanics or Einsteinian gravity. However, Mitchell explains that Wolfram believes that nothing can be more complex than a universal computer which forces an upper limit on the complexity that the universe can exhibit\u0026mdash;this is very interesting although I am not sure I agree completely given the unpredictability we read about earlier in the book, particularly in quantum mechanical phenomena. I was nevertheless fascinated by these ideas and will revisit them in the future.\nA connection became apparent to me while reflecting on the chapters on genetic algorithms and cellular automata. On one hand, many processes in nature consists of simple rules but large in number that coalesce into complex behavior. Cellular automata has this idea built into its very structure. In a way, we can say that the mechanism by which nature evolves and produces complexity is comparable to the way in which cellular automata does so. On the other hand, genetic algorithms were inspired by what occurs in nature, namely natural selection and evolution. I found it fascinating that nature utilizes general principles found in cellular automata and that genetic algorithms mimic what is done in nature. This further reinforces the link between computation and living systems.\nInformation Processing Mitchell guides the reader in understanding information processing particularly in living systems. I enjoyed how she uses different levels of programming, high level and machine language, to home in on the concept of abstraction. She mentions that it's relatively easy to imagine how changes in high level code are translated into low level machine language since the tether between the two is tangible and somewhat predictable. She compares this to cellular automata where the ability to create a productive level of abstraction is not present. This is particular to cellular automata but I imagine that it is a limitation that can be applied to much of complex systems as a whole\u0026mdash;this is, creating a high level framework from which many applications can benefit from especially biological applications. The book wonderfully explains information processing both in terms of what information is and how it is processed. It accomplishes this with the help of three real-world examples: the immune system, ant colonies, and biological metabolism. One of my favorite parts\u0026mdash;which Mitchell believes is a quite profound idea\u0026mdash;is that on the {\\it meaning} of information. We can think in terms of inputs and outputs but what does the information {\\it mean} and what part of a system is doing this type of analysis? As Mitchell points out, this is particularly mysterious for systems with no central controller.\nParts IV and V Part IV of Melanie Mitchell's book discusses the science of networks\u0026mdash;a topic in which tremendous progress and development has been made relatively recently. She begins the discussion with Harvard University psychologist, Stanley Milgram. He was one of the first to have devised an experiment designed to understand the degrees of separation in a network\u0026mdash;his experiment is the quintessential example of the small world property in a network.\nProfessor Mitchell introduces networks and gives examples that demonstrate that networks are ubiquitous in our everyday lives. From social networks to epidemiological studies, these fields can and should be explored in the context of network science. She mentions popular names in the network science world: Duncan Watts, Steven Strogratz, Albert-László Barabási, and Réka Albert who all published papers that formed the foundation of network science. She mentions that physicists made contributions to the field of network science, which is right in the physics wheelhouse given its mathematical nature and real-world application. Mitchell explains that physicists have been trained to simplify complex problems without losing their essential features. I did enjoy and will attempt to commit to memory the eloquent quote from Duncan Watts, \u0026ldquo;No one descends with such fury and in so great a number as a pack of hungry physicists, adrenalized by the scent of a new problem.\u0026rdquo;\nIt is helpful to the reader to know generally what a network is. Mitchell explains the basics of in-degree, out-degree, and their distributions in a network. She goes into what clustering means and how we think about clustering in the real-world. She gives popular examples such as an airplane's use of hubs to optimize flight itineraries. If one were to create a network whose degree distribution is random, all nodes would have somewhat similar degree and the degree distribution would be considered uniform\u0026mdash;unlike what we see in real-world biological and social networks. Naturally occurring networks exhibit hub structures and skewed degree distributions which is quite interesting. What invisible hand is fine-tuning these networks to acquire these specific properties? Mitchell gives us great insight on this. She breaks down the general attributes of networks into two pillars: small-world and scale-free. She explains that when a network has small-world-ness, it exhibits attractive features for a network to have such as robustness and faster communication. A skewed degree distribution makes a network robust to node deletion since hubs are few in number and high in degree. The Milgram experiment is a clear example of how these networks can benefit from efficient information spread whereas disease outbreaks may be exacerbated.\nNetwork science was especially propelled by the use of computers: their increase in computing power and availability of data. Mitchell explains that although real-world networks resembled small-world structures, it was not exact. They are better explained by a property called scale-free that pervades mostly all natural networks. She gives an explanation of using Google's page-rank to show that the world wide web itself is a scale-free network. She goes on the talk about this in terms of scaling invariance and self-similarity and says that this is what is meant by scale-free\u0026mdash;terms that are all synonymous. Another concept she equates to the scale-free property of networks is power law degree distribution. An important part of this discussion is Barab'asi's work on preferential attachment and how this mechanism facilitates the scale-free structure in naturally forming networks.\nIt certainly does aide the reader in having stimulating real-world examples of network structures from which to explore these properties. The examples she delves into are the brain of the worm C. elegans, genetic regulatory networks in our bodies, epidemiological studies, and even ecological insights that the reader can learn from. Mitchell not only explains that the brain of a worm is found to have small-world structure, she also encourages the reader to consider a rather provocative question: \u0026ldquo;Why would evolution favor brain networks with the small-world property?\u0026quot;. Two main ideas stem from this question\u0026mdash;the resilience of scale-free network structures and energy efficiency for global information processing. A fully connected network would use entirely too much energy to complete similar tasks. Mitchell briefly mentions synchronization at the end of the brain example. I understand this topic can get much more involved with how nature utilizes synchronization. The synchronization of fire flies is especially interesting\u0026mdash;more of this can be found in an article written by Renato Mirollo and Steven Strogatz, \u0026ldquo;Synchronization of Pulse-Coupled Biological Oscillators\u0026rdquo;.\nMitchell naturally segues into the topic of scaling. The start of this chapter reminded me of Galileo's Square-Cube Law where he essentially argues that structures cannot simply be scaled up ad infinitum. The core of the argument involves recognizing that volume grows as the cube of the multiplier and the strength of support grows only as the cross-sectional area or square of the multiplier. One of the key messages with regards to scaling is that metabolic rate does not scale linearly with $bodymass$ but rather with $bodymass^{\\frac{3}{4}}$. This occurs in a myriad of creatures and shows that they become more efficient as the scaling grows. This power law distribution of metabolic rate versus body-mass is referred to as Kleiber's law. James Brown, Brian Enquist, and Geoffrey West played pivotal roles in forming the metabolic scaling theory. Geoffrey West wrote a popular book on this subject as well that the general audience can appreciate: \u0026ldquo;Scale: The Universal Laws of Growth, Innovation, Sustainability, and the Pace of Life in Organisms, Cities, Economies, and Companies\u0026rdquo;. He elaborates on how cities and economies tend to exhibit similar power law distributions when they are scaled up as well. Mitchell clearly explains Zipf's law\u0026mdash;she emphasizes it's significance and ubiquity and also provides some insight into why this power-law distribution tends to naturally occur. Mitchell shares that this is an important open problem in complexity science but I was particularly interested in Mandelbrot's argument that the simultaneous optimization of information content and transmission leads directly to Zipf's law.\nThe conclusion of the book serves the reader in several ways. It ties various concepts together mentioned throughout the book and gives a historical account of the key players that contributed to the field of complex systems. It also explains the goal of complexity as a science while sharing the honest opinions of complexity enthusiasts and critics, alike. Mitchell candidly addresses the major challenges of complexity science such as the lack of an all-encompassing mathematical framework from which complexity can be studied. Most importantly, it leaves us with the refreshing hope for future scientists to work diligently to explore the possibility of a grand unified theory of complexity and to discover what Strogatz refers to as the \u0026ldquo;conceptual equivalent of calculus\u0026rdquo;.\n","date":1566777600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1566777600,"objectID":"dbf835e684cf4c0df5598581c6559f79","permalink":"/post/complexity-reflection/","publishdate":"2019-08-26T00:00:00Z","relpermalink":"/post/complexity-reflection/","section":"post","summary":"Reflect on the reading of Melanie Mitchell's Complexity","tags":["Networks","Mathematics","Complex Systems","Books"],"title":"Complexity — A Guided Tour","type":"post"},{"authors":["Eric Peña"],"categories":["Posts"],"content":"Chicagoan Fast My morning commute to work in the heart of downtown Chicago was very regular: Enjoy blazing hot coffee and listen to an interesting podcast all while super-speed-walking all the way to the office. I often think how much time I would save by teleporting to the office instead. Even while often walking faster than most on the busy morning sidewalks, there are folks that zoom past me but still appear to be walking gracefully.\nTo start, let’s break speed walking down to two main factors: long legs and step frequency (which differs from walking speed). I like to think I take advantage of both of these to maintain optimal walking speed (without looking too ridiculous). The general question to myself was this:\nFor someone whose legs are longer than mine, how much faster do I have to walk to keep up? Another way to ask this is, how are the leg length and step-frequency related? If two people, Person A and Person B, are walking at the same step frequency but Person B has longer legs than Person A by a factor of alpha (alpha \u0026gt; 0), Person B will clearly have higher walking speed. Therefore, you can ask by what factor does Person A’s step frequency has to increase to keep up with Person B while walking down the street.\nLet’s go through it logically together. Let's draw the some simple person possible:\nGiven how we're thinking about this problem, the important values we should be interested in is Leg Length and Step Frequency. The angle created by the legs may be important to so let's lable it for now.\nFirst Step (Literally) What happens when one step is taken by Person A and Person B The distance that each person goes in one step is given by:\n$$d_A = 2A \\sin\\left(\\frac{\\alpha_A}{2}\\right)$$ $$d_B = 2B \\sin\\left(\\frac{\\alpha_B}{2}\\right)$$\nWhere $A$ and $B$ are the length of the legs of Person A and Person B, respectively.\nLet's simplify some things before we generalize the problem:\n$$\\tilde{A} = 2A$$ $$\\tilde{B} = 2B$$ $$\\gamma = \\sin\\left(\\frac{\\alpha_A}{2}\\right) = \\sin\\left(\\frac{\\alpha_B}{2}\\right)$$ $$d_A = \\tilde{A} \\gamma$$ $$d_B = \\tilde{B} \\gamma$$\nMore Steps As shown above, we've made the assumption that $\\theta_A = \\theta_B$. Let's generalize this to more than one step. Here we will introduce a person's Step Frequency, $s_A$ and $s_B$, defined as how many steps a person takes per unit time, $t$.\n$$d_A(t) = \\tilde{A} \\gamma s_A t$$ $$d_B(t) = \\tilde{B} \\gamma s_B t$$\nThe general form can be thought of as the linear relationship:\n$$d = \\kappa s t$$\nwhere $\\kappa_A = \\tilde{A} \\gamma$ or $\\kappa_B = \\tilde{B} \\gamma$.\nKeep Up! Here is the main problem for us to go through in order to answer the original question. Let's make Person B have longer legs than Person A by a factor of $x$.\n$$B = x A$$\nGenerally, since Person B has longer legs, the Step Frequency of Person A, $s_A$, has to increase to keep up.\nNow let's look at the ratio $\\frac{d_B}{d_A}$:\n$$\\frac{d_B}{d_A} = \\frac{2 x A \\gamma s_B t}{2 A \\gamma s_A t} = \\frac{x s_B}{s_A}$$\nTo make distance the same between the two people, we'll make: $\\frac{d_B}{d_A} = 1$\n$$\\frac{d_B}{d_A} = 1 = \\frac{x s_B}{s_A}$$ $$s_A = x s_B$$\nWHAT THE HECK DID WE LEARN? If Person B has legs longer than Person A by a factor of $x$ and $\\theta_A$ = $\\theta_B$, then Person A can keep up by increasing their step frequency by $x$. Basically Person A can move their legs faster by this factor to keep up with Person B.\nThis is very simplified. What happens if $\\theta_A \\neq \\theta_B$? Are there other factors to consider? THAT'S ALL, GOTTA RUN ","date":1556582400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556582400,"objectID":"b48d0900fd05c4b182ca2794e0118f3d","permalink":"/post/speedwalking/","publishdate":"2019-04-30T00:00:00Z","relpermalink":"/post/speedwalking/","section":"post","summary":"Exploring relationships of factors that contribute to walking fast","tags":["Mathematics","Modeling"],"title":"Speed Walking in Chicago","type":"post"},{"authors":["Eric Peña"],"categories":["Posts"],"content":"Motivation:\n General Relativity Inertia Tensor Stress Tensor  It took me a whole week figure out what a tensor actually is. You will find many definitions and some are only partially correct. Let's walk through the different explanations and learn how to think about them.\n (Array Definition) Tensor = Multi-dimensional array of numbers (scalars (rank 0), vectors (rank 1), matricies (rank 2), etc.). This is true in a sense but there is a truer geometrical meaning behind the concept of a tensor. (Coordinate Definition) Tensor = an object that is invariant under a change of coordinates and has components that change in a special, predictable way under a change of coordinates. This is also true but let's dive even deeper to learn how a tensor allows this behavior to take place. (Abstract Definition) Tensor = a collection of vectors and covectors combined together using the tensor product  The important thing to keep in mind is that vectors exist independently of their components and their components depend on the coordinate system used to define vectors.\nChanging Coordinate Systems Let's go from an old basis to a new basis\nOld Basis: {$\\vec{e_1}, \\vec{e_2}$} New Basis: {$\\tilde{\\vec{e_1}}, \\tilde{\\vec{e_2}}$} Forward Transformation Suppose: $$\\tilde{\\vec{e_1}} = 2\\vec{e_1}+1\\vec{e_2}$$ $$\\tilde{\\vec{e_2}} = -\\frac{1}{2}\\vec{e_1}+\\frac{1}{4}\\vec{e_2}$$ $$F = \\begin{pmatrix}2 \u0026amp; 1\\\\ -\\frac{1}{2} \u0026amp; \\frac{1}{4}\\end{pmatrix}$$ where $F$ is the Forward Transformation Matrix.\nBackward Transformation This would make the backward transformation: $$\\vec{e_1} = \\frac{1}{4}\\tilde{\\vec{e_1}}+(-1)\\tilde{\\vec{e_2}}$$ $$\\vec{e_2} = \\frac{1}{2}\\tilde{\\vec{e_1}}+2\\tilde{\\vec{e_2}}$$ $$B = \\begin{pmatrix}\\frac{1}{4} \u0026amp; -1\\\\ \\frac{1}{2} \u0026amp; 2\\end{pmatrix}$$\nForward and Backward Transformation $$F \\cdot B = \\begin{pmatrix}2 \u0026amp; 1\\\\ -\\frac{1}{2} \u0026amp; \\frac{1}{4}\\end{pmatrix} \\begin{pmatrix}\\frac{1}{4} \u0026amp; -1\\\\ \\frac{1}{2} \u0026amp; 2\\end{pmatrix} = \\begin{pmatrix}1 \u0026amp; 0\\\\ 0 \u0026amp; 1\\end{pmatrix}$$\nIn general: $$F \\cdot B = \\delta_{ij}$$ $$F = B^{-1}; B = F^{-1}$$ $$\\tilde{\\vec{e_i}} = \\sum_{j=1}^{n} F_{ij} \\vec{e_j}$$ $$\\vec{e_i} = \\sum_{j=1}^{n} B_{ij} \\tilde{\\vec{e_j}}$$\nVectors Vectors are the first example of a tensor. Vectors are invariant but their components are NOT invariant. It is also important to know that not all vectors are geometrical Euclidean vectors. Some vectors that are harder to visualize.\nThe transformation rules for vectors behave in an opposite way compared to the basis vectors {$\\vec{e_1}, \\vec{e_2}$}\n$$\\vec{v} = \\sum_{j=1}^{n}v_j \\vec{e_j} = \\sum_{i=1}^{n} \\tilde{v_i} \\tilde{\\vec{e_i}}$$\n$$\\vec{v} = \\sum_{j=1}^{n} v_j \\vec{e_j} = \\sum_{j=1}^{n} v_j \\left( \\sum_{j=1}^{n} B_{ij} \\tilde{\\vec{e_j}} \\right) = \\sum_{i=1}^{n} \\left( \\sum_{j=1}^{n} B_{ij} v_j \\right) \\tilde{\\vec{e_i}}$$\nSo this shows that: $$\\tilde{v_i} = \\sum_{j=1}^{n} B_{ij} v_j$$ Which basically means that if you want to define the vector is the new basis, we have to use the backwards transformation matrix. This will take some getting used to since it is opposite of the unit basis. For this reason, vectors are said to contravary and are even called contravariant vectors.\n    Basis Vectors     $$\\tilde{\\vec{e_i}} = \\sum_{j=1}^{n} F_{ij} \\vec{e_j}$$ $$\\tilde{v_i} = \\sum_{j=1}^{n} B_{ij} v_j$$   $$\\vec{e_i} = \\sum_{j=1}^{n} B_{ij} \\tilde{\\vec{e_j}}$$ $$v_i = \\sum_{j=1}^{n} F_{ij} \\tilde{v_j}$$     # Notation In tensor calculus, notation can be tricky so it will be helpful to keep a couple tips about notation in mind:  Upper indicies represent contravariant components Lower indicies represent covariant components Einstein notation uses the upper and lower indicies and also drops the $\\sum$ symbol When a covector $\\alpha_j$ is acting on a vector $v^j$, it can be written as $\\alpha_j v^j$ and is assumed to be the sum: $$\\alpha_j v^j = \\sum_{j=1}^n \\alpha_j v^j = \\alpha_1 v^1 + \\alpha_2 v^2 + \\alpha_3 v^3 + \u0026hellip; + \\alpha_n v^n$$ Using this new notation convention, the formulas in the table above can be written as:      Basis Vectors     $$\\tilde{\\vec{e_i}} = F_i^j \\vec{e_j}$$ $$\\tilde{v^i} = B_j^i v^j$$   $$\\vec{e_i} = B_i^j \\tilde{\\vec{e_j}}$$ $$v^i = F_j^i \\tilde{v^j}$$     Covectors Covectors may be harder to visualize since it differs from the arrow Euclidean vectors that is often used in physics. Here are a couple initial notes about covectors:\n Covectors can be thought of as row vectors but clarification is needed for this. Row vectors in this sense are not necessarily column vectors flipped on their side. This is only true when using an orthonormal basis. If the basis is not orthonormal, it is more apparent how row vectors are different from column vectors. It is better to think of covectors as functions that act on vectors and map them to real numbers:  $$\\alpha: V \\rightarrow \\mathbb{R}$$\n When we visualize vectors, we think of them as Euclidean vectors with components in a system of coordinates. A covector can be visualized as directed stacks of lines (or surfaces). Below are a few images that can help visualize covectors:  The inner product is a mechanism used to combine a covector and vector. The output is a number that represents the number of surfaces of the covector that are pierced by the vector.\nCovector Rules To Keep In Mind: Covector acting on a vector: $$\\alpha(\\vec{v}) = \\alpha_1 v^1 + \\alpha_2 v^2 + \\alpha_3 v^3 + \u0026hellip; + \\alpha_n v^n = \\sum_{j=1}^n \\alpha_j v^j$$\nProperties of Linearity: $$\\alpha(\\vec{v} + \\vec{w}) = \\alpha(\\vec{v}) + \\alpha(\\vec{w})$$\n$$\\alpha(n \\vec{v}) = n \\alpha(\\vec{v})$$\n$$(\\beta + \\gamma)(\\vec{v}) = \\beta(\\vec{v}) + \\gamma(\\vec{v})$$\nVector Spaces:\n When scaling and combining vectors, a vector space $V$ is spanned Covectors can also be scaled with scalars and combined using addition and multiplication. The vector space spanned by covectors is called the \u0026ldquo;Dual Vector Space\u0026rdquo;, $V^*$.  Linear Maps ","date":1555718400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555718400,"objectID":"b0b101f304586efb4ff0fe924763a69b","permalink":"/post/tensors/","publishdate":"2019-04-20T00:00:00Z","relpermalink":"/post/tensors/","section":"post","summary":"True Basics of Tensors and Covectors in Mathematics","tags":["Mathematics","Modeling"],"title":"Introduction to Tensors","type":"post"},{"authors":["Eric Peña"],"categories":["Posts"],"content":"Keeping Up With Complex Systems Science News It can be difficult to find time to keep up with interesting science, especially when articles are dense and abstruse. With an unfortunate name like complex systems, keeping up with the intersting news can be a daunting task. Here are a few resources that I use to keep up with the fascinating world of complex systems and systems engineering.\n Santa Fe Institute  Sante Fe Institute Complexity Explorer  Quanta Magazine  Nature The Nature journal has a Complexity page that shows the latest new for complex systems.\n","date":1553990400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1553990400,"objectID":"8d083e2aaf6e75597547605d21459014","permalink":"/post/news/","publishdate":"2019-03-31T00:00:00Z","relpermalink":"/post/news/","section":"post","summary":"Learn about the latest news in complexity and system science","tags":["Complex Systems","Modeling"],"title":"Complex Systems News Resources","type":"post"},{"authors":null,"categories":null,"content":"War Simulation in Python Game designer Greg Costikyan has observed that since there are no choices in the game, and all outcomes are random, it cannot be considered a game by some definitions. I chose to program this game because its complete random chance feature. It was an opportunity to practice python and writing recursive functions. The objective of the game is to win all cards. A 52-card deck is divided evenly among the players, giving each a down stack. In unison, each player reveals the top card of their deck—this is a \u0026ldquo;battle\u0026rdquo;-and the player with the higher card takes both of the cards played and moves them to their reserves stack. The reserves stack is used when there are no longer cards to play in hand.\nIf the two cards played are of equal value, then there is a \u0026ldquo;war\u0026rdquo;. Both players place the next three cards from their hand face down (depending on the variant) and then another card face-up. The owner of the higher face-up card wins the war and adds all six cards on the table to their reserves deck. If the face-up cards are again equal then the battle repeats with another set of face-down/up cards. This repeats until one player's face-up card is higher than their opponent's. This is the part of the game where recursion is helpful. In theory, there can be any number of \u0026ldquo;wars\u0026rdquo; only constrained by the number of cards in the deck. Most descriptions of War are unclear about what happens if a player runs out of cards during a war. In this variant, the player immediately loses.\nBelow are several simulations that were run to explore game behavior\nSimple Game This is a shorter game than average with 3 wars which can be identified by the lines with steeper slopes. This is a slightly longer game with only 4 wars which occur on card flip: 48, 90, 117, and 152. Blowing Up There is \u0026ldquo;blowing up\u0026rdquo; behavior for some games as well. This behavior is typically exacerbated by wars won by the same player.\n                  Triple War When wars occur consecutively, a mass number of cards are moved at once. The example below shows a triple war happening which led Player 2 winning the game. The war began at card flip 698.\nNumber of Wars Per Game What is the War and Game Length relationship? One question that we can ask is how does the number was wars in a game relate to the length of the game itself. I modified the program so that it simulated 1000 games and plotted the number of wars versus the length of each game. Below is the result of this simulation.\nAs you can see, there is a strong linear relationship between the these two quantities. The $R^2 \\approx 1$ value is a helpful indicator of this. The $R^2$ and linear equation are:\n$$R^2 = 0.9225$$ $$y(x)=0.0549x+1.2212$$\nHow many battles are played before a war breaks out? This slope tells us that there is a war every approximately 19 \u0026ldquo;battles\u0026rdquo; (where a battle is a single card flip). To prove this by dividing the game length data by 19 and replotting. This would make every x-axis unit equal to 19 battles. If our claim is true, there should be a one-to-one relationship between our new unit and the number of wars per game. Let's plot it:\nThe trendline has an equation whose slope is close to 1. This is a good sign that our value of 19 is a nice estimate.\n$$y(x) = 1.0391x+1.4576$$\nDistribution of Quantities It may be helpful to know how the game length or war count themselves are distributed. Below are two histgrams that can give insight into their spread. From the two plots below, we can see that these two distribution are somewhat normal with a slight right skew.\nChange The Size Of The War! When two cards are equal a war begins. In this variant of the game, three additional cards are played face-down and a fourth card is used to do another comparison. This is essentially what a \u0026ldquo;war\u0026rdquo; is in this game. We can change the size of the wars - which means we can change the number of face-down cards we throw down before we do another comparison. Here is a table:\n    War Size Meaning     War Size = 2 2 face-down cards before comparing the 3th card during war   War Size = 3 3 face-down cards before comparing the 4th card during war   War Size = 4 2 face-down cards before comparing the 5th card during war     It would be helpful to plot the WC versus GL plot for each war size. From the plot we can observe how the slope of the linear regression equation changes (or how the \u0026ldquo;war per battle\u0026rdquo; value changes with war size). Click on plot below to see it in detail:\nHow does Average Game Length and War Count change with War Size The plot below is a clear picture into how the averages and medians change when we change war size\nIt appears that the larger the war size, the more normal the distribution becomes since the average and median approach the same value.\nAnother way of looking at the game length for different values of war size would be with a layered bar graph. When the data is ordered and plotted with each war size being a layer, we can create the following graph.\nThis graph also shows that the larger the War Size, the smaller the Game Length. Is there anything else we can look into for the analysis of this game?\nThe Code The program has been written in Python and is copied below for those interested.\n# Title: War Simulation # Date: 3/16/2019 # Author: Eric Pena from random import shuffle import random import pandas as pd import matplotlib.pyplot as plt # Create Deck and shuffle it deck = [] deck = range(13) * 4 shuffle(deck) # Deal the cards player1 = deck[::2] player2 = deck[1::2] # Create Reserve Piles player1_res = [] player2_res = [] # Define more variables topcard = 0 # Game counter turn = 1 # Calculate the total cards a player has: hand + reserves #---------------------------------------------------------------------------------------------------------------------------------------------- def total_cards(h, r): return (len(h) + len(r)) # Recursive function that happens when war starts\t#---------------------------------------------------------------------------------------------------------------------------------------------- def idw(player1, player2, player1_res, player2_res, jackpot): # DEBUG print \u0026quot;WAR BREAKS OUT...\u0026quot; # Add reserve to hand and shuffle if hand is less than 4 cards: if (len(player1) \u0026lt; 4): player1.extend(player1_res) player1_res = [] shuffle(player1) if (len(player2) \u0026lt; 4): player2.extend(player2_res) player2_res = [] shuffle(player2) # If this is still not enough cards, clear the cards and stop the game if (len(player1) \u0026lt; 4 or len(player2) \u0026lt; 4): player1, player2, player1_res, player2_res = ([] for i in range(4)) return player1, player2, player1_res, player2_res # Remove top three cards and put them in reserve pile jackpot.extend([player1[0], player1[1], player1[2], player2[0], player2[1], player2[2]]) player1 = player1[3:] player2 = player2[3:] # Use fourth card to compare if player1[topcard] \u0026gt; player2[topcard]: print \u0026quot;PLAYER 1 WINS WAR: \u0026quot; + str(player1[topcard]) + \u0026quot; - \u0026quot; + str(player2[topcard]) player1_res.extend([player1[topcard], player2[topcard]]) player1_res.extend(jackpot) # Remove cards from hand player1 = player1[1:] player2 = player2[1:] return player1, player2, player1_res, player2_res elif player1[topcard] \u0026lt; player2[topcard]: print \u0026quot;PLAYER 2 WINS WAR: \u0026quot; + str(player1[topcard]) + \u0026quot; - \u0026quot; + str(player2[topcard]) player2_res.extend([player1[topcard], player2[topcard]]) player2_res.extend(jackpot) # Remove cards from hand player1 = player1[1:] player2 = player2[1:] return player1, player2, player1_res, player2_res else:\tprint \u0026quot;ANOTHER WAR BEGINS: \u0026quot; + str(player1[topcard]) + \u0026quot; - \u0026quot; + str(player2[topcard]) jackpot.extend([player1[0], player2[0]]) player1 = player1[1:] player2 = player2[1:] return idw(player1, player2, player1_res, player2_res, jackpot) # Start the game #---------------------------------------------------------------------------------------------------------------------------------------------- def play_game(player1, player2, player1_res, player2_res, turn): # Create a record of the game cols = [\u0026quot;Round\u0026quot;, \u0026quot;P1 card\u0026quot;, \u0026quot;P2 card\u0026quot;, \u0026quot;P1 t-len\u0026quot;, \u0026quot;P2 t-len\u0026quot;, \u0026quot;P1 h-len\u0026quot;, \u0026quot;P2 h-len\u0026quot;] datarec = pd.DataFrame(columns = cols) while (len(player1) != 0 and len(player2) != 0): print \u0026quot;Round: \u0026quot; + str(turn) + \u0026quot;\\t|\\t\u0026quot; + \\ str(player1[topcard]) + \u0026quot;\\t|\\t\u0026quot; + \\ str(player2[topcard]) + \u0026quot;\\t|\\t\u0026quot; + \\ str(total_cards(player1, player1_res)) + \u0026quot;\\t|\\t\u0026quot; + \\ str(total_cards(player2, player2_res)) + \u0026quot;\\t|\\t\u0026quot; + \\ str(len(player1)) + \u0026quot;\\t|\\t\u0026quot; + \\ str(len(player2)) + \u0026quot;\\t|\\t\u0026quot; + \\ str(total_cards(player1, player1_res) + total_cards(player2, player2_res)) # Add data to pandas dataframe: datarec.loc[turn - 1] = [turn, player1[topcard], player2[topcard], total_cards(player1, player1_res), total_cards(player2, player2_res), len(player1), len(player2)] # Flip top cards and assign: if player1[topcard] \u0026gt; player2[topcard]: player1_res.extend([player1[topcard], player2[topcard]]) # Remove topcard from hands player1 = player1[1:] player2 = player2[1:] elif player1[topcard] \u0026lt; player2[topcard]: player2_res.extend([player1[topcard], player2[topcard]]) # Remove topcard from hands player1 = player1[1:] player2 = player2[1:] else: print \u0026quot;TOP: \u0026quot; + str(player1[topcard]) + \u0026quot; - \u0026quot; + str(player2[topcard]) player1, player2, player1_res, player2_res = idw(player1, player2, player1_res, player2_res,[]) # Replenish Cards if len(player1) == 0: player1 = player1_res shuffle(player1) player1_res = [] # it1 = 0 if len(player2) == 0: player2 = player2_res shuffle(player2) player2_res = [] # it2 = 0 turn += 1 return player1, player2, player1_res, player2_res, datarec, turn #---------------------------------------------------------------------------------------------------------------------------------------------- # MAIN PROGRAM: print \u0026quot;Round: \u0026quot; + \u0026quot;\\t\\t|\\t\u0026quot; + \u0026quot;P1 card\u0026quot; + \u0026quot;\\t|\\t\u0026quot; + \u0026quot;P2 card\u0026quot; + \u0026quot;\\t|\\t\u0026quot; + \u0026quot;P1-T\u0026quot; + \u0026quot;\\t|\\t\u0026quot; + \u0026quot;P2-T\u0026quot; + \u0026quot;\\t|\\t\u0026quot; + \u0026quot;P1-H\u0026quot; + \u0026quot;\\t|\\t\u0026quot; + \u0026quot;P2-H\u0026quot; player1, player2, player1_res, player2_res, df, turn = play_game(player1, player2, player1_res, player2_res, turn) plt.plot(df[\u0026quot;Round\u0026quot;], df[\u0026quot;P1 t-len\u0026quot;]) plt.plot(df[\u0026quot;Round\u0026quot;], df[\u0026quot;P2 t-len\u0026quot;]) plt.legend(['Player 1', 'Player 2']) plt.title(\u0026quot;War Simulation\u0026quot;) plt.xlabel(\u0026quot;Card Flips\u0026quot;) plt.ylabel(\u0026quot;Number of Cards For Each Player\u0026quot;) plt.show()  ","date":1552694400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1552694400,"objectID":"781f2f62702cd37833d622b76f3b4bb1","permalink":"/project/war-project/","publishdate":"2019-03-16T00:00:00Z","relpermalink":"/project/war-project/","section":"project","summary":"Simulation of the Card Game - I Declare War","tags":["Modeling","Programming"],"title":"Declare War Project","type":"project"},{"authors":["Eric Peña"],"categories":["Posts"],"content":"\u0026ldquo;Truth is ever to be found in simplicity, and not in the multiplicity and confusion of things.\u0026ldquo;\nIsaac Newton I approached R in the same way I would any language. I immediately delve into for-loops, conditional statements, user-defined functions, classes, and so on. I didn't pay much attention to data types at first - assuming they're not much different than what I've seen already. I found myself using dataframes and matricies often with low confidence and a lingering confusion. I needed to know how these R data structures were related. I finally created these notes for myself to get a grip on the topic. Hopefully you find value in them as well.\nThe data structures we will cover:\n Vectors Matricies Arrays Lists Data Frames Factors Tables  For each data type, we will review the basics of:\n Creation Adding Element Deleting Elements Indexing Filtering and More   Vectors Introduction All elements in an R vector must have the same mode: integer, numeric, character, logical, complex, etc.\nCreation x \u0026lt;- c(88, 12, 23, 74) x  ## [1] 88 12 23 74  Adding Element Adding -44 to vector x:\nx \u0026lt;- c(x,-44) x  ## [1] 88 12 23 74 -44  or:\nx[5] \u0026lt;- -44 x  ## [1] 88 12 23 74 -44  Remove Element Remove 23 from x:\nx \u0026lt;- x[-3] x  ## [1] 88 12 74 -44  It's possible to remove several items at once:\nx \u0026lt;- x[-3:-5] x  ## [1] 88 12  Indexing x \u0026lt;- rep(1,10) x[4] \u0026lt;- 3 x  ## [1] 1 1 1 3 1 1 1 1 1 1  x[4]  ## [1] 3  Filtering x[6] \u0026lt;- 5 x[9] \u0026lt;- 2 x[x \u0026gt; 2]  ## [1] 3 5  Combining Vectors Find the length of a vector with length(x):\nWhen adding two vectors, the lengths of the vectors must be the same or one must be a multiple length of the other. When a vector isn't long enough to add to another vectors, it will keep repeating itself however many times it needs in order for the lengths to match.\ny \u0026lt;- x + x; y  ## [1] 2 2 2 6 2 10 2 2 4 2  z \u0026lt;- x + c(1,2,3,4,5); z  ## [1] 2 3 4 7 6 6 3 4 6 6  error \u0026lt;- x + c(1,2,3,4); error  ## Warning in x + c(1, 2, 3, 4): longer object length is not a multiple of ## shorter object length ## [1] 2 3 4 7 2 7 4 5 3 3   Matricies Introduction A matrix is essentially a vector with two attributes. All the columns in a matrix must have the same mode: integer, numeric, character, logical, complex, etc. in the same way it does for a vector. Matricies are special cases of a more general R type of object: arrays - which we will read about next. Arrays can be multidimensional.\nCreation One way to create a matrix:\ny \u0026lt;- matrix(c(1,2,3,4), nrow = 2, ncol = 2)  or simply:\ny \u0026lt;- matrix(c(1,2,3,4), nrow = 2) y  ## [,1] [,2] ## [1,] 1 3 ## [2,] 2 4  Using the byrow argument (default = FALSE):\nm \u0026lt;- matrix(c(1,2,3,4,5,6), nrow = 2, byrow = T) m  ## [,1] [,2] [,3] ## [1,] 1 2 3 ## [2,] 4 5 6  Adding and Removing Rows and Columns Rows and columns may be added and deleting from a matrix with operations analogous to the vector operations of adding and deleting. These functions are rbind and cbind.\nAdding a column:\nones_column \u0026lt;- matrix(rep(1,2)); ones_column; m  ## [,1] ## [1,] 1 ## [2,] 1 ## [,1] [,2] [,3] ## [1,] 1 2 3 ## [2,] 4 5 6  cbind(m, ones_column)  ## [,1] [,2] [,3] [,4] ## [1,] 1 2 3 1 ## [2,] 4 5 6 1  Adding a row: (don't forgot to adjust the row number: nrow = 1)\nones_row \u0026lt;- matrix(rep(1,3), nrow = 1); ones_row; m  ## [,1] [,2] [,3] ## [1,] 1 1 1 ## [,1] [,2] [,3] ## [1,] 1 2 3 ## [2,] 4 5 6  rbind(ones_row, m)  ## [,1] [,2] [,3] ## [1,] 1 1 1 ## [2,] 1 2 3 ## [3,] 4 5 6  Rows may be added by creating matricies and copying:\nnew_matrix \u0026lt;- matrix(nrow = 3, ncol = 3) addded_row \u0026lt;- matrix(c(7,8,9), nrow = 1) new_matrix[1:2,1:3] \u0026lt;- m new_matrix[3,1:3] \u0026lt;- addded_row new_matrix  ## [,1] [,2] [,3] ## [1,] 1 2 3 ## [2,] 4 5 6 ## [3,] 7 8 9  You can use rbind and cbind to reassign values. This is a form of deleting data.\nm \u0026lt;- matrix(1:6, nrow = 3); m  ## [,1] [,2] ## [1,] 1 4 ## [2,] 2 5 ## [3,] 3 6  m \u0026lt;- m[c(1,3),]; m  ## [,1] [,2] ## [1,] 1 4 ## [2,] 3 6  Indexing To retrieve information from a matrix:\nm[,2]  ## [1] 4 6  m[2,]  ## [1] 3 6  m[2,2]  ## [1] 6  Values may be changed in a matrix as well:\nm[2,2] \u0026lt;- 66; m  ## [,1] [,2] ## [1,] 1 4 ## [2,] 3 66  Filtering x \u0026lt;- matrix(c(1,2,3,2,3,4), nrow = 3, byrow = F); x  ## [,1] [,2] ## [1,] 1 2 ## [2,] 2 3 ## [3,] 3 4  x[x[,2] \u0026gt;= 3]  ## [1] 2 3 3 4  j \u0026lt;- x[,2] \u0026gt;= 3 x[j,]  ## [,1] [,2] ## [1,] 2 3 ## [2,] 3 4  Matrix Math y  ## [,1] [,2] ## [1,] 1 3 ## [2,] 2 4  Mathematical Matrix Multiplication\ny %*% y  ## [,1] [,2] ## [1,] 7 15 ## [2,] 10 22  Mathematical Muliplication of Matrix by Scalar\n3*y  ## [,1] [,2] ## [1,] 3 9 ## [2,] 6 12  Mathematical Matrix Addition\ny + y  ## [,1] [,2] ## [1,] 2 6 ## [2,] 4 8   Arrays Introduction The mechanics of an array is very similar to that of a matrix in R. Unlike a matrix, an array can represent data in higher than two dimensions. We may build a three-dimensional array by conbining two matricies, we can build four-dimensional arrays by combining two or more three-dimensional arrays, and so on.\n Lists Introduction List are unique in that not all elements have to be of the same mode. List structures can combine different types. An R list is similar to a Python dictionary or C struct. List form the foundation for data frames, object oriented programming (R classes), and more.\nCreation If we wanted to create an employee database, we could start with:\nj \u0026lt;- list(name = \u0026quot;Eric\u0026quot;, salary = 45000, union = T) j  ## $name ## [1] \u0026quot;Eric\u0026quot; ## ## $salary ## [1] 45000 ## ## $union ## [1] TRUE  The component names are called tags.\nAdding Element New components can be added after a list is created:\nz \u0026lt;- list(a = \u0026quot;abc\u0026quot;, b = 12) z  ## $a ## [1] \u0026quot;abc\u0026quot; ## ## $b ## [1] 12  z$c \u0026lt;- \u0026quot;sailing\u0026quot; # add a c component z  ## $a ## [1] \u0026quot;abc\u0026quot; ## ## $b ## [1] 12 ## ## $c ## [1] \u0026quot;sailing\u0026quot;  Adding component can also be done via a vector index:\nz[[4]] \u0026lt;- 28 z[5:7] \u0026lt;- c(F,T,T) z  ## $a ## [1] \u0026quot;abc\u0026quot; ## ## $b ## [1] 12 ## ## $c ## [1] \u0026quot;sailing\u0026quot; ## ## [[4]] ## [1] 28 ## ## [[5]] ## [1] FALSE ## ## [[6]] ## [1] TRUE ## ## [[7]] ## [1] TRUE  You can also concatenate lists:\ncat \u0026lt;- c(list(\u0026quot;Joe\u0026quot;, 55000, T), list(5)); cat  ## [[1]] ## [1] \u0026quot;Joe\u0026quot; ## ## [[2]] ## [1] 55000 ## ## [[3]] ## [1] TRUE ## ## [[4]] ## [1] 5  Remove Element You can delete a list component by setting it equal to NULL:\nz$b \u0026lt;- NULL z  ## $a ## [1] \u0026quot;abc\u0026quot; ## ## $c ## [1] \u0026quot;sailing\u0026quot; ## ## [[3]] ## [1] 28 ## ## [[4]] ## [1] FALSE ## ## [[5]] ## [1] TRUE ## ## [[6]] ## [1] TRUE  Indexing You can access a list component in several different ways:\nj$salary  ## [1] 45000  j[[\u0026quot;salary\u0026quot;]]  ## [1] 45000  j[[2]]  ## [1] 45000  What's the deal with the single and double brackets?\nIf single brackets are used, the result is another list - a sublist of the original.\nj1 \u0026lt;- j[1:2]; j1  ## $name ## [1] \u0026quot;Eric\u0026quot; ## ## $salary ## [1] 45000  If double brackets are used, it is for referring to a single component and is return in the type of the component.\nj[[2]]  ## [1] 45000  The following returns an error since it's trying to return several components using a function that is meant to return one:\n# j[[1:2]]  Filtering Accessing list components:\nnames(j)  ## [1] \u0026quot;name\u0026quot; \u0026quot;salary\u0026quot; \u0026quot;union\u0026quot;  We can also get the specific values instead:\nulj \u0026lt;- unlist(j); ulj  ## name salary union ## \u0026quot;Eric\u0026quot; \u0026quot;45000\u0026quot; \u0026quot;TRUE\u0026quot;  Each values above has a name. This name may be removed with the following function:\nnames(ulj) \u0026lt;- NULL ulj  ## [1] \u0026quot;Eric\u0026quot; \u0026quot;45000\u0026quot; \u0026quot;TRUE\u0026quot;  Using lapply() and sapply() functions This applies a specific function on each of the compoenents of a list and returns another list:\nlapply(list(1:3,25:29), median)  ## [[1]] ## [1] 2 ## ## [[2]] ## [1] 27  sapply() returns a vector-valued answer:\nsapply(list(1:3,25:29), median)  ## [1] 2 27  Recursive Lists You can have lists within lists:\nb \u0026lt;- list(u = 5, v = 12) c \u0026lt;- list(w = 13) a \u0026lt;- list(b, c) a  ## [[1]] ## [[1]]$u ## [1] 5 ## ## [[1]]$v ## [1] 12 ## ## ## [[2]] ## [[2]]$w ## [1] 13  TIP: The concatenate function c() has an optional argument recursive, which controls whether flattening occurs when recursive lists are combined.\n Data Frames Introduction Data frames are similar to a two dimensional matrix in that it contains rows and columns structure. However, data frame are heterogeneous; columns can be different modes. Technically, a data frame is a list whose components are equal-lengthed vectors as the columns of the data frame. Data frame are commonly used when doing data manipulation and other data analysis techniques in R.\nCreation Creating a data frame from scratch:\nscientists \u0026lt;- c(\u0026quot;Einstein\u0026quot;, \u0026quot;Newton\u0026quot;) born \u0026lt;- c(1879, 1642) d \u0026lt;- data.frame(scientists, born, stringsAsFactors = FALSE) d  ## scientists born ## 1 Einstein 1879 ## 2 Newton 1642  If the named argument stringsAsFactors is not specified, then by default, stringsAsFactors will be TRUE.\nData frames can also be created from external files (.csv, .mtp, .xls, .spss, .txt) using: mydata = read.csv(\u0026quot;mydata.csv\u0026quot;, header = TRUE)  mydata = read.mtp(\u0026quot;mydata.mtp\u0026quot;) # read from .mtp file  mydata = read.xls(\u0026quot;mydata.xls\u0026quot;) # read from first sheet  mydata = read.spss(\u0026quot;myfile\u0026quot;, to.data.frame=TRUE)  mydata = read.table(\u0026quot;mydata.txt\u0026quot;)  and many more options.\nAdding Element The rbind() and cbind() matrix functions also work in data frames to add new rows or columns of the same length.\nAdding a new row:\nd1  ## kids ages ## 1 jack 12 ## 2 Jill 10  rbind(d1, list(\u0026quot;laura\u0026quot;, 19))  ## kids ages ## 1 jack 12 ## 2 Jill 10 ## 3 laura 19  Adding a column\nRemove Element Data deletion in a data frame is similar to that of a vector.\nd2  ## kids ages ## 1 jack 12 ## 2 Jill 10 ## 3 laura 19  d2 \u0026lt;- d2[-2,] d2  ## kids ages ## 1 jack 12 ## 3 laura 19  Indexing d[[1]]  ## [1] \u0026quot;Einstein\u0026quot; \u0026quot;Newton\u0026quot;  d$scientists  ## [1] \u0026quot;Einstein\u0026quot; \u0026quot;Newton\u0026quot;  We may also access elements in a matrix-like way we well:\nd[,1]  ## [1] \u0026quot;Einstein\u0026quot; \u0026quot;Newton\u0026quot;  It can be helpful to know the structure of the data frame and is easy to achieve:\nstr(d)  ## 'data.frame': 2 obs. of 2 variables: ## $ scientists: chr \u0026quot;Einstein\u0026quot; \u0026quot;Newton\u0026quot; ## $ born : num 1879 1642  Filtering Let's take a look at how to filter data in a data frame:\ncars \u0026lt;- cars[c(\u0026quot;mpg\u0026quot;, \u0026quot;hp\u0026quot;, \u0026quot;wt\u0026quot;,\u0026quot;cyl\u0026quot;)] head(cars)  ## mpg hp wt cyl ## Mazda RX4 21.0 110 2.620 6 ## Mazda RX4 Wag 21.0 110 2.875 6 ## Datsun 710 22.8 93 2.320 4 ## Hornet 4 Drive 21.4 110 3.215 6 ## Hornet Sportabout 18.7 175 3.440 8 ## Valiant 18.1 105 3.460 6  cars[cars$cyl == 8,]  ## mpg hp wt cyl ## Hornet Sportabout 18.7 175 3.440 8 ## Duster 360 14.3 245 3.570 8 ## Merc 450SE 16.4 180 4.070 8 ## Merc 450SL 17.3 180 3.730 8 ## Merc 450SLC 15.2 180 3.780 8 ## Cadillac Fleetwood 10.4 205 5.250 8 ## Lincoln Continental 10.4 215 5.424 8 ## Chrysler Imperial 14.7 230 5.345 8 ## Dodge Challenger 15.5 150 3.520 8 ## AMC Javelin 15.2 150 3.435 8 ## Camaro Z28 13.3 245 3.840 8 ## Pontiac Firebird 19.2 175 3.845 8 ## Ford Pantera L 15.8 264 3.170 8 ## Maserati Bora 15.0 335 3.570 8  cars[,c(\u0026quot;mpg\u0026quot;, \u0026quot;hp\u0026quot;)][cars$wt \u0026lt;= 4,]  ## mpg hp ## Mazda RX4 21.0 110 ## Mazda RX4 Wag 21.0 110 ## Datsun 710 22.8 93 ## Hornet 4 Drive 21.4 110 ## Hornet Sportabout 18.7 175 ## Valiant 18.1 105 ## Duster 360 14.3 245 ## Merc 240D 24.4 62 ## Merc 230 22.8 95 ## Merc 280 19.2 123 ## Merc 280C 17.8 123 ## Merc 450SL 17.3 180 ## Merc 450SLC 15.2 180 ## Fiat 128 32.4 66 ## Honda Civic 30.4 52 ## Toyota Corolla 33.9 65 ## Toyota Corona 21.5 97 ## Dodge Challenger 15.5 150 ## AMC Javelin 15.2 150 ## Camaro Z28 13.3 245 ## Pontiac Firebird 19.2 175 ## Fiat X1-9 27.3 66 ## Porsche 914-2 26.0 91 ## Lotus Europa 30.4 113 ## Ford Pantera L 15.8 264 ## Ferrari Dino 19.7 175 ## Maserati Bora 15.0 335 ## Volvo 142E 21.4 109   Factors Introduction The motivation for factors comes from the concept of categorical data in statistics. An R factor may be viewed as a vector with more information added. The extra information consists of a record of the distinct values on that vector, called levels.\nCreation x \u0026lt;- c(5, 12, 13, 12) xf \u0026lt;- factor(x) xf  ## [1] 5 12 13 12 ## Levels: 5 12 13  The distinct values in xf: 5, 12, and 13 are the levels\nstr(xf)  ## Factor w/ 3 levels \u0026quot;5\u0026quot;,\u0026quot;12\u0026quot;,\u0026quot;13\u0026quot;: 1 2 3 2  unclass(xf)  ## [1] 1 2 3 2 ## attr(,\u0026quot;levels\u0026quot;) ## [1] \u0026quot;5\u0026quot; \u0026quot;12\u0026quot; \u0026quot;13\u0026quot;  length(xf)  ## [1] 4  Adding Element Future new levels can be anticipated as well:\nx \u0026lt;- c(5, 12, 13, 12) xff \u0026lt;- factor(x, levels = c(5, 12, 13, 88)) xff  ## [1] 5 12 13 12 ## Levels: 5 12 13 88  xff[2] \u0026lt;- 88 xff  ## [1] 5 88 13 12 ## Levels: 5 12 13 88  Although you cannot add a value that doesn't have a level associated with it:\nxff[2] \u0026lt;- 28  ## invalid factor level, NA generated ### \u0026lt;span style=\u0026quot;color:#E74C3C\u0026quot;\u0026gt;Remove Element\u0026lt;/span\u0026gt; ### \u0026lt;span style=\u0026quot;color:#E74C3C\u0026quot;\u0026gt;Indexing\u0026lt;/span\u0026gt; ### \u0026lt;span style=\u0026quot;color:#E74C3C\u0026quot;\u0026gt;Filtering\u0026lt;/span\u0026gt; ### \u0026lt;span style=\u0026quot;color:#E74C3C\u0026quot;\u0026gt;Math\u0026lt;/span\u0026gt;   Tables Introduction Creation Adding Element Remove Element Indexing Filtering Math ","date":1551657600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551657600,"objectID":"eb964048fd7407b5d6668e2cfe4efdcd","permalink":"/post/r-data-types/","publishdate":"2019-03-04T00:00:00Z","relpermalink":"/post/r-data-types/","section":"post","summary":"Learn the Basics of R Data Types","tags":["Programming","R"],"title":"R Programming Data Types","type":"post"},{"authors":["Eric Peña"],"categories":["Posts"],"content":"Graphs may be represented in the form of a matrix. Main types of graphs that may be represented are:\n Simple Graph Multigraph Directed Graph Weighted Graph Bipartite Graph  Directed Graph Directed graphs are graphs that contain edges with direction. Vertices may have inward and outward edges.\nUnlike adjacency matricies for simped graphs, adjacency matricies for directed graphs are non-symmetric. Elements of an adjacency matrix for a directed graph may be denoted as: $$A_{ij}$$ which represents an edge from vertex $j$ to $i$.\n Figure 1 — Directed graph with four verticies  The corresponding adjacency matrix for the graph above is: $$A = \\begin{pmatrix}0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0\\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0\\\\ 1 \u0026amp; 1 \u0026amp; 0 \u0026amp; 0\\\\ 1 \u0026amp; 1 \u0026amp; 0 \u0026amp; 0 \\end{pmatrix}$$\nCocitation The cocitation of two vertices $i$ and $j$ in a directed network is the number of vertices that have outgoing edges pointing to both $i$ and $j$. We can see that:\n$$A_{ik}A_{jk} = 1$$ if $i$ and $j$ are both cited by $k$. If we sum over all these elements we get the following relation:\n$$C_{ij} = \\sum\\limits_{k=1}^n A_{ik}A_{jk} = \\sum\\limits_{k=1}^n A_{ik}A_{kj}^T = AA^T $$ This is a cocitation network for which there is an edge between $i$ and $j$ if $C_{ij} \u0026gt; 0$, for $i \\neq j$.\nThe diagonal elements of the cocitation matrix are given by:\n$$C_{ii} = \\sum\\limits_{k=1}^n A_{ik}^2 = \\sum\\limits_{k=1}^n A_{ik}$$ In constructing the cocitation network we ignore these diagonal elements, meaning that the network's adjacency matrix is equal to the cocitation matrix but with all the diagonal elements set to zero.\nBibliographic Coupling Cocitation and Bibliographic coupling are similar mathematically but give different results. They're both affected by the number of in and out edges. Bibliographic Coupling of two vertices are the number of other vertices to which both $i$ and $j$ point to. Bibliographic Coupling is general more stable since the number of citations can vary with time. Bibliographic Coupling is known at time of publishing and doesn't change at all. This may or may not be a good thing depending on the situation. Mathematically, it can be described by the following:\n$$B_{ij} = \\sum\\limits_{k=1}^n A_{ki}A_{kj} = \\sum\\limits_{k=1}^n A_{ik}^TA_{kj} = A^TA $$ The diagonal elements of $\\textbf{B}$ are:\n$$B_{ii} = \\sum\\limits_{k=1}^n A_{ki}^2 = \\sum\\limits_{k=1}^n A_{ki}$$ $B_{ii}$ is equal to the number of other vertices that vertex $i$ points to - the number of papers $i$ cites.\n Figure 2 — Shows cocitation and bibliographic coupling network comparison  Hypergraphs Networks with link that join more than two vertices are called hypergraphs. These types of graphs are useful when representing family relations for example. Edges that relate more than two vertices are called hyperedges. In sociology, these networks may be called affiliation networks.\nBipartite Networks Hypergraphs may be difficult to deal with and represent mathematically but a tool that can help are bipartite graphs - a way of conveniently representing the hypergraph structure. In sociology, this may be called: two-mode networks. Edges only exist between two vertices of unlike-types.\nThe adjacency matrix for a bipartite graph is a rectangular matrix called an incidence matrix which is a $g$ by $n$ matrix where $g$ is the number of groups and $n$ are the number of members in the groups.\n $$B_{ij} = \\begin{cases} 1, \u0026 \\textit{if vertex j belongs to group i} \\\\ 0, \u0026 \\textit{otherwise} \\end{cases}$$   Figure 3 — Bipartite Graph  The adjancency matrix for the bipartite graph above can be written as a $4$ by $5$ matrix:\n$$B = \\begin{pmatrix}1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0\\\\1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 0\\\\0 \u0026amp; 1 \u0026amp; 1 \u0026amp; 0 \u0026amp; 1\\\\0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 1 \u0026amp; 1\\end{pmatrix}$$\nThis is a much easier way of representing the hypergraph of actors to movies for example. For much info, read section 6.6 (p.125) of Networks - An Introduction (Newman).\nThe bipartite graph can be broken down even further by making two one-mode projections. One projection can be made with the groups side and another can be made with members side. These projections have the benefit of being simpler to study but are less powerful because information is lost through these projections.\nThe two one-mode projections in words are:\n The number of groups for which members $i$ and $j$ are both a part of. This is an $n$ x $n$ matrix: $$P = B^TB$$ The number of common members of groups $i$ and $j$. This is a $g$ x $g$ matrix: $$P'=BB^T$$  Quick Thought Naturally you want to relate this to cociation and bibliographic coupling networks but it may be confusing to do so. The main difference between cocitation and bibliographic coupling is the direction of the arrows. This bipartite network consists of two different types of nodes and un-directed edges. Therefore, you may have some cyclic thinking if you try to relate them too much. Although The first projection (the one on the members) is similar to the cocitation network in that the diagonals should be ignored and forced to be zero.\nInformation Loss Although these projections make life a little easier, it does come at a cost: loss of information. Some of the things we loose are the number of groups in the network and the exact membership of each group. If we make the projection weighted graphs, we can at least get information as to how many commons groups a pair of vertices share for example.\nTrees A tree is a connected, undirected network that contains no closed loops. Connected means that every vertex in the network is reachable from every other via some path through the network. A network can also consists of two or more parts. If the individual parts of the network are trees, the then network as a whole is considered a forest. There are leaves on a tree - vertices with one edge on them but topologically, there isn't really a root.\nThe most important property of a tree is that, since there are no closed loops, there is only one path between any pair of vertices. In a forest, there is at most one path but there may be none.\nAnother very useful property of trees is that a tree of $n$ vertices always has $n-1$ edges. The reverse is also true: any connected network with $n$ vertices and $n-1$ edges is a tree. If such a network were not a tree then there must be a loop in the network somewhere, implying that we could remove an edge without disconnecting any part of the network.\nPlanar Network Simply put, a planar network is a network that can be drawn on a plane without having any edges cross. All trees are planar but most of the time, network are not planar (e.g., citation networks, metabolic networks, internet, etc.). Some networks are forced to be planar because of physics space constraints such as rivers or road networks.\nThese types of networks play an important role in the four-color theorem which state that the number of colors required to color a graph in this way is called the chromatic number of the graph and many mathematical results are known about chromatic numbers.\nAn important to point out is that there is a method of determining if a network is planar. It's fairly easy to tell by observation if the network is small but when the network is very large, a general method is required.\nKuratowski's Theorem: Every non-planar network contains a least one subgraph that is an expansion of $K_5$ and $UG$. (Read more about this on p. 132 of Networks - an Introduction (Newman)).\nDegree Mean Degree We will denote the degree of vertex $i$ by $k_i$. For an undirected graph of n vertices the degree can be written in terms of the adjacency matrix as:\n$$k_i = \\sum\\limits_{j=1}^n A_{ij}$$ Every edge in an undirected graph has two ends and if there are m edges in total then there are $2m$ ends of edges. But the number of ends of edges is also equal to the sum of the degrees of all the vertices, so\n$$2m = \\sum\\limits_{i=1}^n k_i$$ Another way of writing this that is more intuitive is:\n$$m = \\frac{1}{2}\\sum\\limits_{i=1}^n k_i = \\frac{1}{2}\\sum\\limits_{ij}^n A_{ij}$$ The mean degree $c$ of an undirected graph is:\n$$c = \\frac{1}{n} \\sum\\limits_{i=1}^n k_i$$ And combining this with the earlier equation:\n$$c = \\frac{2m}{n}$$\nDensity The maximum possible number of edges in a simple graph is $\\binom{n}{2} = \\frac{1}{2}n(n-1)$. The connectance or density $\\rho$ of a graph is the fraction of these edges that are actually present:\n$$\\rho = \\frac{m}{\\binom{n}{2}}=\\frac{2m}{n(n-1)}=\\frac{c}{n-1}$$\nWhen the network is sufficiently large, $\\rho$ may be approximated with just $\\frac{c}{n}$.\nA network where $\\rho$ tends to a constant as $n \\rightarrow \\infty$ is said to be dense. A network in which $\\rho \\rightarrow 0$ as $n \\rightarrow \\infty$ is said to be sparse.\nDirected Network Degree Vertex degrees in a directed network are more complicated. They are broken up into in-degree and out-degree. If $A_{ij}$ is the adjacency matrix of a directed network, the *in* and *out* degree can be written as:\n$$k_i^{in} = \\sum\\limits_{j=1}^n A_{ij},\\ \\ \\ k_j^{out} = \\sum\\limits_{i=1}^n A_{ij}$$ We also know the number of edges are:\n$$m = \\sum\t\\limits_{i=1}^n k_i^{in} = \\sum\\limits_{j=1}^n k_j^{out} = \\sum\t\\limits_{ij} A_{ij}$$ As far as the mean degree of directed networks:\n$$c_{in} = \\frac{1}{n} \\sum\\limits_{i=1}^n k_i^{in} = \\frac{1}{n} \\sum\\limits_{j=1}^n k_j^{out} = c_{out}$$ Combining these two relations, the mean degree can concisely be written as:\n$$c = \\frac{m}{n}$$\nPaths A path along a network is a route across the network moving from vertex to vertex along the edges. In a directed network, the path can on go in the direction of the edge but can go either way for an undirected network. A path may reach a vertex or go along an edge it has seen before. A path that does not intersect itself is considered a self-avoiding path. Geodesic paths and Hamiltonian paths are two special cases of self-avoiding paths.\nThe number of paths of length $r$ may be important to study and can be calculated for directed and undirected networks. We will use the fact that for directed and undirected networks, $A_{ij}$ is 1 if there is an edge from vertex $j$ to vertex $i$, and 0 otherwise. We can start by asking how many paths of length 2 are there in a network. Imagine we want to study all paths of length 2 from $j$ to $i$ via $k$. The product $A_{ik}A_{kj}$ is 1 where there is a path of length 2 from $j$ to $i$ via $k$, and 0 otherwise.\n$$N_{ij}^{(2)} = \\sum\\limits_{k=1}^n A_{ik}A_{kj}=\\left[A^2\\right]_{ij}$$ We can study the path of length 3 as well. The product $A_{ik}A_{kl}A_{lj}$ is 1 where there exists a path of length 3, and 0 otherwise.\n$$N_{ij}^{(3)} = \\sum\\limits_{k,l=1}^n A_{ik}A_{kl}A_{lj}=\\left[A^3\\right]_{ij}$$ Generalizing to any length $r$ gives:\n$$N_{ij}^{r}=\\left[A^r\\right]_{ij}$$ There is a proof of induction on page 137 of Network - An Introduction (Newman).\nAnother important thing to consider are loops in a network. The number of loops may be calculated as well.\n$$L_r = \\sum\\limits_{i=1}^n\\left[A^r\\right]_{ii}=Tr A^r$$ There \u0026lsquo;Tr\u0026rsquo; is the trace of a matrix. The number of loops can be written in terms of the eigenvalues of the adjacency matrix as well. The adjacency matrix can be written as $A=UKU^T$ where $U$ is the orthogonal matrix of eigenvectors and $K$ is the orthogonal matrix of eigenvalues:\n$$A^r = (UKU^T)^r = UK^rU^T$$\n$$L_r = Tr(UK^rU^T)=Tr(U^TUK^r)=Tr(k^r)=\\sum\\limits_i k_i^r$$ Where $k_i$ is the $i^{th}$ eigenvalue of the adjacency matrix. This applies to directed and undirected graphs. There is one important thing to note when learning about counting the number of loops on length r. For each consideration below, the calculation for determining the number of loops uses the following criteria for counting distinct loops.\n Although there are loop paths that have the same vertices and same order, if there are different starting points, then they are considered separate loops.  $$1\\rightarrow 2\\rightarrow 3 \\rightarrow 1 \\ \\ \\ and \\ \\ \\ 2\\rightarrow 3\\rightarrow 2 \\rightarrow 1$$\n If loops are in the opposite direction, they are counted as distinct loops. $$1 \\rightarrow 2 \\rightarrow 3 \\rightarrow 1 \\ \\ \\ and \\ \\ \\ 1 \\rightarrow 3 \\rightarrow 2 \\rightarrow 1$$  Geodesic Paths A geodesic path is shortest network distance between vertices in question. This is also called geodesic distance or shortest distance. Mathematically, a geodesic distance is the smallest value of r such that $\\left[ A^r \\right]_{ij} \u0026gt; 0$ between vertices $i$ and $j$.\nIt may be the case that no shortest distance exists (for example: for separate components of the network where the distance may be said to be infinity). Another interesting fact - If a path intesects itself, it has a loop and therefore cannot be a geodesic path since it can be shortened by removing this loop.\nThe diameter of a graph is the length of the longest geodesic path between any pair of vertices in the network for which a path actually exists.\nEulerian and Hamiltonian Paths  Eulerian Path: a path that traverses each edge in the network exactly once Hamiltonian Path: a path that visits each vertex exactly once  If there are any vertex degree greater than 2, then the Eulerian path is not self-avoiding since it has to visit vertices more than once in order to traverse tall their edges.\nKronigsberg Bridges This problem becomes finding an Eulerian path on this network of bridges and the name is in honor of Euler who presented this problem. Euler observed that since any Eulerian path must both enter and leave every vertex it passes (except for the first and last), there can at most be two vertices with odd degree. All four of the vertices in the Kronigsberg Problem has odd degree. More precisely, there can only be 2 or 0 vertices of odd degree for an Eulerian condition to be possible. With this logic, Euler proved the Kronigsberg problem has no solution.\n","date":1544918400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1544918400,"objectID":"e49aace3e499bcd1d05926e38e7c7d4b","permalink":"/post/network-theory/","publishdate":"2018-12-16T00:00:00Z","relpermalink":"/post/network-theory/","section":"post","summary":"Introduction to Mathematics of Network Theory","tags":["Complex Systems","Networks","Mathematics","Modeling"],"title":"Mathematics of Network Theory","type":"post"},{"authors":["Eric Peña"],"categories":["Posts"],"content":"Generalized Coordinates and Conservation Laws From the Lagrangian Formulation of Theoretical Mechanics These are selected notes from a group of topics I find of particular interest. Although I assume some previous knowledge of classical mechanics from you, I still provide a brief overview of what the Lagrangian method is, where it comes from, how it relates to the more familiar Newtonian formulation, and how these beautiful laws of nature imply conserved quantities in everyday systems. The core of these notes include how we can simplify the Lagrangian method by observing conserved quantities by means of cyclic or \u0026ldquo;ignorable\u0026rdquo; generalized coordinates. The Lagrangian is invariant under variations of these types of coordinates. I will explain how cyclic coordinates and Lagrangian invariance imply conservation laws. There are several results that relate Lagrangian invariance and conserved quantities and they are referred to as Noether's theorem. I am happy to share what I have learned with you!\nOverview Let's start with simple laws of motion. They describe how mechanical systems evolve in time given certain conditions and constraints. Consider yourself standing on the St. Louis Arch (Gateway Arch, whose width and height are 630 ft.) for some God awful reason. You hold out an apple with your hand and drop it so that it is falling towards the Earth. We can predict, for example, where the apple will be at some later time by using an equation of motion. Say we took air resistance into account or that it then falls into a huge pool of oil or dropping a water balloon instead that oscillates in free space or dropping a single water droplet while it's raining. Does the rate at which the water droplet accumulate \u0026ldquo;water-mass\u0026rdquo; increase? And if this drop then fell into the pool of oil\u0026hellip; and if the pool sits on a spring\u0026hellip; or two springs\u0026hellip; or an infinite number of springs and etc. We can study a slew of systems using equations of motion (and some canny logical intuition). Newtonian and Lagrangian mechanics are just a couple ways a obtaining these types of descriptions of systems we experience everyday.\nThe most obvious difference between these methods is the Newtonian method utilize the external forces of a system and how they apply in some defined coordinate plane while the Lagrangian focuses on the energy the system is experiencing. Now we can begin talking about the Lagrangian and how related these methods actually are.\nThe Lagrangian can be written as:\n$$ \\mathcal{L} = T - U$$\nThe kinetic energy $T$ and the potential energy $U$ are used to make the Lagrangian and the Lagrangian is used to find the equations of motion with something called the Lagrange equations. It can be written as:\n$$\\frac{\\partial \\mathcal{L}}{\\partial q_i}=\\frac{d}{dt}\\frac{\\partial \\mathcal{L}}{\\partial \\dot{q}_i}$$\nwhere $q_i$ are the generalized coordinates that we are using. Since this is still the overview, I will briefly describe where the Lagrange equation comes from.\nThe Lagrange equation is a subset of a far broader area of mathematics called the Calculus of Variations or Variational Calculus. It involves finding the maximum and minimum of a quantity that can be expressed as an integral. The general form of what is called the variational problem is:\n$$S=\\int_{x_1}^{x_2} f[y(x), y\u0026rsquo;(x), x]dx$$\nThe important part is finding the equation $y(x)$ such that the $S$ integral is stationary (which means infinitesimal variations of the path $y(x)$ doesn't change the value of the integral). After a tedious derivation, we are left with what is called the Euler-Lagrange equation. Remember that this result is purely mathematical and hasn't been applied to our physics world quite yet.\nWe can talk about these variational methods for pages but let's get to the meat of it all. The reason why variational calculus and the Euler-Lagrange equation are so important is because when the function $f[y(x), y\u0026rsquo;(x), x]$ within the integral is the Lagrangian (defined at the top of the page), the integral is called the action integral and the function that makes the action integral stationary is the equation of motion of the particle in question.\nThis result is stated in what is called Hamilton's Principle. It tells us that if we know the energy (and therefore the Lagrangian) of a system, then we can know about its motion and how it evolves through time. Hamilton's Principle is as follows:\nHamilton's Principle The actual path which a particle follows between two points 1 and 2 in a given time interval, $t_1$ to $t_2$, is such that the action integral\n$$S=\\int_{t_1}^{t_2} \\mathcal{L} dt$$\nis stationary when taken along the actual path.\nNow we may go back to the Lagrange equation and see that it must provide us with the path that an actual particle will travel that experiences the forces and energy described by the Lagrangian. $$\\frac{\\partial \\mathcal{L}}{\\partial q_i}=\\frac{d}{dt}\\frac{\\partial \\mathcal{L}}{\\partial \\dot{q}_i}$$\nIf what has been written so far seems vague or a bit generalized, it is because this was intended to be more of a reminder than an introduction. Let's finish this overview with the relationship between the Newtonian and Lagrangian formulations. The equations that are obtained by these methods must be equal; physics does not change depending on the language we use to describe it; they really are one and the same. Just because Newton's laws are usually explicitly written in terms of force doesn't mean we can't express it in terms of another quantity like momentum for example: $$F = ma = m\\dot{v} = \\dot{p}$$ Let's not forget how related force and energy really are:\n$$\\Delta T = T_2 - T_1 = \\int_{1}^{2}\\textbf{F} \\cdot d\\textbf{r}$$\n$$U(\\textbf{r}) = -\\int_{r_0}^r F(\\textbf{r}') \\cdot d\\textbf{r}\u0026lsquo;$$ To relate Lagrangian and Newtonian methods more directly:\nEuler-Lagrange Equation $$\\frac{\\partial \\mathcal{L}}{\\partial q_i}=\\frac{d}{dt}\\frac{\\partial \\mathcal{L}}{\\partial \\dot{q}_i}$$ $$\\frac{\\partial \\mathcal{L}}{\\partial q_i} = F_i\\ \\ \\ and\\ \\ \\ \\frac{\\partial \\mathcal{L}}{\\partial \\dot{q}_i} \\equiv p_i$$ These are referred to as generalized forces and generalized momenta. We may start our discussion of generalized ignorable coordinates and conservation laws now!\nQuick Fun Fact! There also exists a Hamiltonian formulation of Classical Mechanics that takes advantage of its own coordinate system called Canonical Coordinates.\nGeneralized Coordinates Generalized momenta and generalized forces are not the same thing as the familiar force and momentum we are used to. We can still relate momentum and force in the usual manner: $$F_i = \\frac{d}{dt}p_i,$$ except these are understood to be defined using generalized coordinates. The fact that generalized force $=$ rate of change of generalized momentum should not be surprising. A direct way to think of generalized coordinates is to describe the complete motion of a system in the fewest number of coordinates. Consider a pendulum bob for one moment (yes, another pendulum).\nWe have a choice of using Cartesian coordinates to describe the motion of this bob or any other coordinate system we can dream up. The downside of using Cartesian coordinates $(x,y,z)$, is that $x$, $y$, and $z$ must constantly compensate one another to assure the length L remains constant. We can imagine all the combinations of values that satisfy $(\\sqrt{x^2+y^2})^2+l^2(1-z)^2=constant$. Long story short, spherical (or polar) coordinates $(r, \\theta, \\phi)$ are the most appropriate for this problem for obvious symmetrical advantages and can be considered the generalized coordinates that define our system.\nNow that we have mentioned what generalized coordinates are, we can gain more insight on what generalized momenta is. Ordinary momentum by definition is $p = mv$ where $v$ is one time derivative away from a position variable: $p = m (\\dot{x}+\\dot{y}+\\dot{z})$. So we can easily see that generalized momenta is simple the mass of an object times the time derivative of its generalized position vectors! Simple! Generalized force can be found the same way except with two time derivatives. $F_t$ in the Figure 1 is the generalized force of the pendulum system. This pendulum can escape from the x-y grid universe and be thought of as moving along one generalized coordinate, $\\theta(t)$. (The length of the pendulum, L, if fixed but if it weren't, $r(t)$ could be another generalized coordinate used to describe the system).\nCyclic Coordinates When the Lagrangian of a system is independent of a generalized coordinate $q_i$, that coordinate is sometimes called a cyclic or ignorable coordinate. Saying the Lagrangian is independent of a particular variable is exactly what it sounds like, neither the kinetic nor the potential energy depend on this quantity. This leads directly to the fact that there exists a conserved quantity!\nWe can generally express a Lagrangian that is independent of some generalized coordinate $q_2$ as: $$\\mathcal{L}=\\mathcal{L}(q_1, q_3, q_4, \\cdots, \\dot{q}_1, \\dot{q}_2, \\dot{q}_3, \\dot{q}_4, \\cdots, t)$$\nWhat this means exactly, is that the generalized momentum that corresponds to $q_2$ is conserved. This can be written as: $$\\frac{d}{dt}\\frac{\\partial \\mathcal{L}}{\\partial \\dot{q}_2} = \\frac{\\partial \\mathcal{L}}{\\partial q_2} = 0$$ $$\\frac{\\partial \\mathcal{L}}{\\partial \\dot{q}_2} = \\kappa$$ where $\\kappa$ is constant. We can say that this system exhibits conservation of angular momentum!\nThis makes solving equations of motion using Lagrangian even easier than before!\nLet's take advantage of this property by examining the $\\mathcal{L}$ of a standard classical mechanics problem (one of which never gets old). It is stated as follows:\nProblem A mass $m$ is free to slide on a frictionless table and is connected, via a string that passes through a hole in the table, to a mass $M$ that hangs below. Assume that $M$ moves in a vertical line only, and assume that the string always remains taut. Figure 2 shows a moment in time of this situation.\nThe Lagrangian is as follows: $$\\mathcal{L}=T-U$$ $$\\mathcal{L}=\\frac{1}{2}M \\dot{r}^2+\\frac{1}{2}m(\\dot{r}^2+r^2\\dot{\\theta}^2)+Mg(l-r)$$ The important thing to notice about this expression is that there is no $\\theta$ variable in it anywhere. The Lagrangian is said to be invariant under variations of the generalized coordinate $\\theta$. The important conclusion to take away from this is that the momentum that corresponds to $\\theta$ is conserved or in this case, the angular momentum $mr^2\\dot{\\theta}$. Therefore without much investigating we can quickly see that $\\frac{d}{dt}(mr^2\\dot{\\theta})=0$. This comes directly from the Euler-Langrange equation obtained by varying $\\theta$:\n$$\\frac{\\partial \\mathcal{L}}{\\partial \\theta}=\\frac{d}{dt}\\frac{\\partial \\mathcal{L}}{\\partial \\dot{\\theta}}$$ $$0 = \\frac{d}{dt}(mr^2\\dot{\\theta})$$\nThe E-L equation that comes from varying $r$ is: $$\\frac{\\partial \\mathcal{L}}{\\partial r}=\\frac{d}{dt}\\frac{\\partial \\mathcal{L}}{\\partial \\dot{r}}$$ $$(M+m)\\ddot{r}=mr\\dot{\\theta}^2-Mg$$\nConservation of Energy Energy is also another quantity that is often conversed in these types of mechanical problems. We will introduce an important claim that touches on this conservation law. First let's give a definition of energy in terms of the Lagrangian: $$E \\equiv (\\sum_{i=1}^{N} \\frac{\\partial \\mathcal{L}}{\\partial \\dot{q}_i} \\dot{q}_i) - \\mathcal{L}$$ This may seem random to define the energy in such a way but don't worry too much about it for now. Without going into too much detail, this result is far from random. In fact, there is a rigorous mathematical reason, called the theory of Legendre transforms, that explains why energy can be written in this form. You see this often in Hamiltonian mechanics since the Hamiltonian is simply the total energy of the system: $T+U$.\nNow we may introduce the claim mentioned earlier:\nIf $\\mathcal{L}$ has no explicit time dependence (that is, if $\\frac{\\partial \\mathcal{L}}{\\partial t} = 0$), then E is conserved (that is, $\\frac{dE}{dt} = 0$), assuming that the motion obeys the E-L equations.\nWithout proving it, the following relation summarizes this claim: $$\\frac{dE}{dt}=-\\frac{\\partial \\mathcal{L}}{\\partial t}.$$\nApplications I programmed this nonlinear double pendulum with Mathematica (Wolfram Language) ","date":1513641600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1513641600,"objectID":"1f4a518dffd21e5947c4e27946d6e4d9","permalink":"/post/gen-coord/","publishdate":"2017-12-19T00:00:00Z","relpermalink":"/post/gen-coord/","section":"post","summary":"Generalized Coordinates and Conservation Laws From the Lagrangian Formulation of Theoretical Mechanics","tags":["Physics","Complex Systems","Modeling","Mathematics"],"title":"Lagrangian Mechanics","type":"post"}]