<!DOCTYPE HTML>


<script type="text/javascript">
    window.MathJax = {
        tex: {
            inlineMath: [['$', '$']],
            displayMath: [['$$', '$$']]
        }
    };
</script>
<script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.js">
</script>

<html lang="en">
	<head>
	  <title>K-Means</title>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<meta name="referrer" content="origin">

	

    <meta name="description" content="Senior Data Scientist
Understanding Complexity Through Data and Statistics">
    
    <meta name="generator" content="Hugo 0.138.0">

    
<link rel="stylesheet" href="../../css/main.min.6470f359d96cadb62114d84a859a08e047c933e85d36b945421da8260b62381977f4f70390c7eab26f30d96e167059bdd0e86e799c562d5d4eba32b5a9d4713c.css" integrity="sha512-ZHDzWdlsrbYhFNhKhZoI4EfJM&#43;hdNrlFQh2oJgtiOBl39PcDkMfqsm8w2W4WcFm90OhueZxWLV1OujK1qdRxPA==">


<noscript><link rel="stylesheet" href="../../css/noscript.min.e6f1ba19697eecfddfbf83ff7181b98181998f163d7005f6ae923451556bf85bef357f43dffe1522b92c1efab7fb38441f479e39b7a03e4313a8ef12b0b01f65.css" integrity="sha512-5vG6GWl&#43;7P3fv4P/cYG5gYGZjxY9cAX2rpI0UVVr&#43;FvvNX9D3/4VIrksHvq3&#43;zhEH0eeObegPkMTqO8SsLAfZQ=="></noscript>





    
    
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="K-Means">
  <meta name="twitter:description" content="The article provides a comprehensive guide to implementing the K-Means clustering algorithm from scratch, exploring its functionality, optimization, and hyperparameter tuning, and compares it with Scikit-Learn&#39;s implementation">
      <meta name="twitter:site" content="@ericpenax">

    <meta property="og:url" content="https://&lt;username&gt;.github.io/posts/k-means/">
  <meta property="og:site_name" content="Eric Peña">
  <meta property="og:title" content="K-Means">
  <meta property="og:description" content="The article provides a comprehensive guide to implementing the K-Means clustering algorithm from scratch, exploring its functionality, optimization, and hyperparameter tuning, and compares it with Scikit-Learn&#39;s implementation">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2021-07-01T00:00:00+00:00">
    <meta property="article:modified_time" content="2021-07-01T00:00:00+00:00">
    <meta property="article:tag" content="Data Science">
    <meta property="article:tag" content="Programming">

    
	</head>
	<body class="landing is-preload">

		
			<div id="page-wrapper">

				
          <header id="header">
            <h1><a href="https://%3cusername%3e.github.io/">Eric Peña</a></h1>
						<nav id="nav">
							<ul>
								<li class="special">
                  <a href="#menu" class="menuToggle" aria-label='Menu'><span>Menu</span></a>
									<div id="menu">
										<ul>
				              
				              <li><a href="../../">Home</a></li>
				              
				              <li><a href="../../about/">About Me</a></li>
				              
				              <li><a href="../../posts/">Posts</a></li>
				              
										</ul>
									</div>
								</li>
							</ul>
						</nav>
					</header>

<article id="main">
  <header >
    <h2>K-Means</h2>
    
	</header>
	<section class="wrapper style5">
		<div class="inner">
      <h1 id="introduction">Introduction</h1>
<p>Imagine we have a scattering of points whose labels or group assignments are completely unknown to us and moreover, we haven&rsquo;t a clue as to the number of groups. Unsupervised clustering helps us in such a situation and allows us to assign a cluster to each point. These clusters are defined by their centroids (centers). The K-Means algorithm will iteratively update these centroids to find the best location for them. It turns out that this clustering problem that K-Means helps solve is a computationally difficult problem (NP-Hard) but nevertheless we will go through the steps in detail here.</p>
<p>It may help understand this algorithm if we were to create the K-Means algorithm completely from scratch to get a deeper understanding of what is happening. This article includes:</p>
<ol>
<li>Simulate data</li>
<li>Create functions used by K-Means</li>
<li>Perform K-Means with specified number of clusters</li>
<li>Define a score value, perform K-Means with different number of clusters, and choosing the best value for this hyperparameter</li>
<li>Performing K-Means with the Scikit-Learn library</li>
<li>Compare performance between our implementation and the Scikit-Learn implementation</li>
</ol>
<h1 id="1-simulate-data">1. Simulate Data</h1>
<ul>
<li>Let&rsquo;s begin with simply simulating some points that we will then use to cluster</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> random
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>n <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>
</span></span><span style="display:flex;"><span>points <span style="color:#f92672">=</span> [[random<span style="color:#f92672">.</span>choice([<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>]) <span style="color:#f92672">+</span> random<span style="color:#f92672">.</span>uniform(<span style="color:#f92672">-</span><span style="color:#ae81ff">0.8</span>, <span style="color:#ae81ff">0.8</span>) <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">2</span>)] <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(n)]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>[p<span style="color:#f92672">.</span>append(<span style="color:#ae81ff">0</span>) <span style="color:#66d9ef">for</span> p <span style="color:#f92672">in</span> points]
</span></span><span style="display:flex;"><span>npoints <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(points)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>scatter(npoints[:,<span style="color:#ae81ff">0</span>], npoints[:,<span style="color:#ae81ff">1</span>], marker<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;o&#39;</span>, c<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;r&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;Scatter Plot of Points&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;X&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;Y&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p><img alt="png" src="../../images/k-means/k-means_5_0.png"></p>
<h1 id="2-define-functions-for-k-means">2. Define Functions For K-Means</h1>
<h3 id="initialize-clusters">Initialize Clusters</h3>
<ul>
<li>Have k-means algorithm &lsquo;find&rsquo; the clusters</li>
<li>Begin by randomly choosing initial cluster values</li>
<li>As we know with k-means, k should be chosen in the beginning. Say we didn&rsquo;t know there were four clusters in reality so we start with $k = 3$</li>
<li>To choose initial clusters, let&rsquo;s take a sample of our data, calculate the means of our $X$ and $Y$ values and assign this to a cluster</li>
<li>Let&rsquo;s say we take a small number of samples just to get rough starting clustering</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">initialize_clusters</span>(points, k):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    clusters <span style="color:#f92672">=</span> [<span style="color:#ae81ff">0</span> <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(k)]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(clusters)):
</span></span><span style="display:flex;"><span>        idx <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>randint(points<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>], size<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>)
</span></span><span style="display:flex;"><span>        sample <span style="color:#f92672">=</span> points[idx, :]
</span></span><span style="display:flex;"><span>        clusters[i] <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>mean(sample, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>        clusters[i][<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>] <span style="color:#f92672">=</span> i
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>array(clusters)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>k <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>
</span></span><span style="display:flex;"><span>clusters <span style="color:#f92672">=</span> initialize_clusters(npoints, k)
</span></span></code></pre></div><h3 id="assign-points-to-a-cluster">Assign Points to a Cluster</h3>
<ul>
<li>Let&rsquo;s go ahead and assign each point to a cluster depending on which one it is closest to</li>
<li>We will need a distance method to define &lsquo;closeness&rsquo;</li>
<li>We will also need a method that allows us to compare each point to all clusters and choose the closes</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">distance</span>(a, b):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>sqrt((b[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">-</span> a[<span style="color:#ae81ff">0</span>])<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span> <span style="color:#f92672">+</span> (b[<span style="color:#ae81ff">1</span>] <span style="color:#f92672">-</span> a[<span style="color:#ae81ff">1</span>])<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">assign_labels</span>(points, clusters):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    lpoints <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>empty((<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">3</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> p <span style="color:#f92672">in</span> points:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        cluster_dist <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> c <span style="color:#f92672">in</span> clusters:
</span></span><span style="display:flex;"><span>            cluster_dist<span style="color:#f92672">.</span>append(distance(p, c))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        p[<span style="color:#ae81ff">2</span>] <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>argmin(cluster_dist)
</span></span><span style="display:flex;"><span>        lpoints <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>vstack((lpoints, p))
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> lpoints
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>lpoints <span style="color:#f92672">=</span> assign_labels(npoints, clusters)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>x <span style="color:#f92672">=</span> lpoints[:, <span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>y <span style="color:#f92672">=</span> lpoints[:, <span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>l <span style="color:#f92672">=</span> lpoints[:, <span style="color:#ae81ff">2</span>]
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>colors<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;r&#39;</span>,<span style="color:#e6db74">&#39;b&#39;</span>,<span style="color:#e6db74">&#39;g&#39;</span>]
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>scatter(x, y, c <span style="color:#f92672">=</span> [colors[int(i)] <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> l])
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;Initial Clusters&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;X&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;Y&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p><img alt="png" src="../../images/k-means/k-means_14_0.png"></p>
<h3 id="update-clusters">Update Clusters</h3>
<ul>
<li>Now that we have initial clusters, we can recalculate the clusters</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">calculate_clusters</span>(points):
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    cluster_label <span style="color:#f92672">=</span> list(set(points[:,<span style="color:#ae81ff">2</span>]))
</span></span><span style="display:flex;"><span>    clusters <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> c <span style="color:#f92672">in</span> cluster_label:
</span></span><span style="display:flex;"><span>        mask <span style="color:#f92672">=</span> points[:, <span style="color:#ae81ff">2</span>] <span style="color:#f92672">==</span> c
</span></span><span style="display:flex;"><span>        clusters<span style="color:#f92672">.</span>append(np<span style="color:#f92672">.</span>mean(points[mask, :], axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>))
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>array(clusters)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>calculate_clusters(npoints)
</span></span></code></pre></div><pre><code>array([[-0.90555932, -0.95877451,  0.        ],
       [ 0.94987571, -1.12258394,  1.        ],
       [-0.24173413,  1.00161447,  2.        ]])
</code></pre>
<ul>
<li>These are the functions needed to perform K-Means. All we have left to do is iteratively apply these functions to obtain optimal values for our clusters.</li>
</ul>
<h1 id="3-perform-k-means-with-k--3">3. Perform K-Means with $k = 3$</h1>
<ul>
<li>Generate new data and assign all points to the same group</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>n <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>
</span></span><span style="display:flex;"><span>points <span style="color:#f92672">=</span> [[random<span style="color:#f92672">.</span>choice([<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>]) <span style="color:#f92672">+</span> random<span style="color:#f92672">.</span>uniform(<span style="color:#f92672">-</span><span style="color:#ae81ff">0.8</span>, <span style="color:#ae81ff">0.8</span>) <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">2</span>)] <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(n)]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>[p<span style="color:#f92672">.</span>append(<span style="color:#ae81ff">0</span>) <span style="color:#66d9ef">for</span> p <span style="color:#f92672">in</span> points]
</span></span><span style="display:flex;"><span>npoints <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(points)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>k <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>
</span></span><span style="display:flex;"><span>iterations <span style="color:#f92672">=</span> <span style="color:#ae81ff">30</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>clusters <span style="color:#f92672">=</span> initialize_clusters(npoints, k)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(iterations):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Assign points to clusters</span>
</span></span><span style="display:flex;"><span>    npoints <span style="color:#f92672">=</span> assign_labels(npoints, clusters)
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Update cluster</span>
</span></span><span style="display:flex;"><span>    clusters <span style="color:#f92672">=</span> calculate_clusters(npoints)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>x <span style="color:#f92672">=</span> npoints[:, <span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>y <span style="color:#f92672">=</span> npoints[:, <span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>l <span style="color:#f92672">=</span> npoints[:, <span style="color:#ae81ff">2</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>colors<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;r&#39;</span>,<span style="color:#e6db74">&#39;b&#39;</span>,<span style="color:#e6db74">&#39;g&#39;</span>, <span style="color:#e6db74">&#39;k&#39;</span>, <span style="color:#e6db74">&#39;y&#39;</span>]
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>scatter(x, y, c <span style="color:#f92672">=</span> [colors[int(i)] <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> l])
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>scatter(clusters[:,<span style="color:#ae81ff">0</span>],clusters[:,<span style="color:#ae81ff">1</span>],s<span style="color:#f92672">=</span><span style="color:#ae81ff">70</span>,marker<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;s&#39;</span>,c<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;k&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;Clusters&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;X&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;Y&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p><img alt="png" src="../../images/k-means/k-means_23_0.png"></p>
<h1 id="4-finding-best-value-for-k">4. Finding Best Value For $k$</h1>
<ul>
<li>We can calculate the sum of squared distances between all points and their respective clusters</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">calculate_score</span>(points, clusters):
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    dist_list <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> p <span style="color:#f92672">in</span> points:
</span></span><span style="display:flex;"><span>        dist_list<span style="color:#f92672">.</span>append(distance(p, clusters[int(p[<span style="color:#ae81ff">2</span>])])<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> sum(dist_list)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>calculate_score(npoints, clusters)
</span></span></code></pre></div><pre><code>63.98898775077078
</code></pre>
<h3 id="iterate-through-and-find-best-k-value-by-plotting-elbow">Iterate through and find best $k$ value by plotting Elbow</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>iterations <span style="color:#f92672">=</span> <span style="color:#ae81ff">50</span>
</span></span><span style="display:flex;"><span>scores <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>colors<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;C&#39;</span> <span style="color:#f92672">+</span> str(i) <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">10</span>)]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> k <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">10</span>):
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    clusters <span style="color:#f92672">=</span> initialize_clusters(npoints, k)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(iterations):
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Assign points to clusters</span>
</span></span><span style="display:flex;"><span>        npoints <span style="color:#f92672">=</span> assign_labels(npoints, clusters)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Update cluster</span>
</span></span><span style="display:flex;"><span>        clusters <span style="color:#f92672">=</span> calculate_clusters(npoints)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    scores<span style="color:#f92672">.</span>append([k, calculate_score(npoints, clusters)])
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> npoints[:, <span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>    y <span style="color:#f92672">=</span> npoints[:, <span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>    l <span style="color:#f92672">=</span> npoints[:, <span style="color:#ae81ff">2</span>]
</span></span><span style="display:flex;"><span>    plt<span style="color:#f92672">.</span>scatter(x, y, c <span style="color:#f92672">=</span> [colors[int(i)] <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> l])
</span></span><span style="display:flex;"><span>    plt<span style="color:#f92672">.</span>scatter(clusters[:,<span style="color:#ae81ff">0</span>],clusters[:,<span style="color:#ae81ff">1</span>],s<span style="color:#f92672">=</span><span style="color:#ae81ff">70</span>,marker<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;s&#39;</span>,c<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;k&#39;</span>)
</span></span><span style="display:flex;"><span>    plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;Clusters&#39;</span>)
</span></span><span style="display:flex;"><span>    plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;X&#39;</span>)
</span></span><span style="display:flex;"><span>    plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;Y&#39;</span>)
</span></span><span style="display:flex;"><span>    plt<span style="color:#f92672">.</span>show()
</span></span><span style="display:flex;"><span>    
</span></span></code></pre></div><p><img alt="png" src="../../images/k-means/k-means_28_0.png"></p>
<p><img alt="png" src="../../images/k-means/k-means_28_1.png"></p>
<p><img alt="png" src="../../images/k-means/k-means_28_2.png"></p>
<p><img alt="png" src="../../images/k-means/k-means_28_3.png"></p>
<p><img alt="png" src="../../images/k-means/k-means_28_4.png"></p>
<p><img alt="png" src="../../images/k-means/k-means_28_5.png"></p>
<p><img alt="png" src="../../images/k-means/k-means_28_6.png"></p>
<p><img alt="png" src="../../images/k-means/k-means_28_7.png"></p>
<p><img alt="png" src="../../images/k-means/k-means_28_8.png"></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot([s[<span style="color:#ae81ff">0</span>] <span style="color:#66d9ef">for</span> s <span style="color:#f92672">in</span> scores], [s[<span style="color:#ae81ff">1</span>] <span style="color:#66d9ef">for</span> s <span style="color:#f92672">in</span> scores], <span style="color:#e6db74">&#39;ro-&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;Elbow Plot&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;k (Number of Clusters)&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;Sum of Within Sum of Squared Errors&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p><img alt="png" src="../../images/k-means/k-means_29_0.png"></p>
<h3 id="found-optimal-hyperparameter-k">Found Optimal Hyperparameter, $k$</h3>
<ul>
<li>We find that 4 is the optimal number of clusters which was the number of clusters used to simulate the original data (with noise).</li>
</ul>
<h1 id="5-using-scikitlearn-library">5. Using ScikitLearn Library</h1>
<ul>
<li>Although we show how KMeans may be implemented ourselves with a few simple ideas, we can take advantage of libraries as well such as ScikitLearn. In fact, it only takes one line!</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.cluster <span style="color:#f92672">import</span> KMeans
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>y_pred <span style="color:#f92672">=</span> KMeans(n_clusters<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)<span style="color:#f92672">.</span>fit(npoints[:, :<span style="color:#ae81ff">2</span>])
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>x <span style="color:#f92672">=</span> npoints[:, <span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>y <span style="color:#f92672">=</span> npoints[:, <span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>l <span style="color:#f92672">=</span> y_pred<span style="color:#f92672">.</span>labels_
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>scatter(x, y, c <span style="color:#f92672">=</span> [colors[int(i)] <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> l])
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>scatter(y_pred<span style="color:#f92672">.</span>cluster_centers_[:,<span style="color:#ae81ff">0</span>], y_pred<span style="color:#f92672">.</span>cluster_centers_[:,<span style="color:#ae81ff">1</span>],s<span style="color:#f92672">=</span><span style="color:#ae81ff">70</span>,marker<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;s&#39;</span>,c<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;k&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;Clusters&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;X&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;Y&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p><img alt="png" src="../../images/k-means/k-means_34_0.png"></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>y_pred<span style="color:#f92672">.</span>inertia_
</span></span></code></pre></div><pre><code>39.46338949369036
</code></pre>
<h1 id="6-comparing-performance">6. Comparing Performance</h1>
<ul>
<li>When compared to the scores we obtained from scrach (when $k = 4$), the scores are VERY similar! Just compare the &ldquo;inertia&rdquo; above with the score for $k = 4$ below.</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>scores
</span></span></code></pre></div><pre><code>[[1, 236.5967940882629],
 [2, 121.32804203454275],
 [3, 63.98898775077078],
 [4, 39.46338949369035],
 [5, 35.048952764699855],
 [6, 33.172015160724094],
 [7, 28.18150296713385],
 [8, 21.647161881862452],
 [9, 21.134201520090667]]
</code></pre>
<h1 id="conclusion">Conclusion</h1>
<h2 id="pros">Pros</h2>
<ul>
<li>Relatively simple to implement.</li>
<li>Scales to large data sets.</li>
<li>Guarantees convergence.</li>
<li>Can warm-start the positions of centroids.</li>
<li>Easily adapts to new examples.</li>
<li>Generalizes to clusters of different shapes and sizes, such as elliptical clusters.</li>
</ul>
<h2 id="cons">Cons</h2>
<ul>
<li>Must choose $k$ manually</li>
<li>Quite dependent on initial centroids</li>
<li>Clustering data of different sizes and densities</li>
<li>Clusters could be &lsquo;dragged&rsquo; by outliers (they may even get their own cluster)</li>
<li>Scales poorly with high number of dimensions (consider projecting data points into lower dimensional space using PCA)</li>
</ul>
<p>We&rsquo;ve completed all of our tasks and hopefully you have a better idea of how the K-Means algorithm works and how to implement it by hand if you needed to.</p>
<h2 id="references">References</h2>
<ol>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html">https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html</a></li>
<li><a href="https://en.wikipedia.org/wiki/K-means_clustering">https://en.wikipedia.org/wiki/K-means_clustering</a></li>
<li><a href="https://en.wikipedia.org/wiki/Spectral_clustering#Relationship_with_k-means">https://en.wikipedia.org/wiki/Spectral_clustering#Relationship_with_k-means</a></li>
</ol>

		</div>
	</section>
</article>
				
					<footer id="footer">
						<ul class="icons">
              
              <li><a href="https://www.linkedin.com/in/eric-pena" class="icon brands fa-linkedin" target="_blank" rel="noopener noreferrer"><span class="label">LinkedIn</span></a></li>
              
              
              <li><a href="https://twitter.com/ericpenax" class="icon brands fa-twitter" target="_blank" rel="noopener noreferrer"><span class="label">Twitter</span></a></li>
              
              
              <li><a href="https://mstdn.science/@ericpena" class="icon brands fa-mastodon" target="_blank" rel="noopener noreferrer"><span class="label">Mastodon</span></a></li>
              
              
              <li><a href="https://github.com/ericpena" class="icon brands fa-github" target="_blank" rel="noopener noreferrer"><span class="label">GitHub</span></a></li>
              
              
              
              
              <li><a href="https://instagram.com/ericpena" class="icon brands fa-instagram" target="_blank" rel="noopener noreferrer"><span class="label">Instagram</span></a></li>
              
              
              
              <li><a href="mailto:eric.pena@binghamton.edu" class="icon solid fa-envelope" target="_blank" rel="noopener noreferrer"><span class="label">Email</span></a></li>
              
              

						</ul>
						<ul class="copyright">
              <li>&copy; 2025 Eric Peña</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
						</ul>
					</footer>

			</div>

      









<script src="../../js/bundle.min.935254271ae3006602cb92b38ba70062a462cefc8d3aa575338369d256bb8422a69fc18f64450e74b7e6c240b20a252f522f3b9f323294bdf9ed466f5fb28ee9.js" integrity="sha512-k1JUJxrjAGYCy5Kzi6cAYqRizvyNOqV1M4Np0la7hCKmn8GPZEUOdLfmwkCyCiUvUi87nzIylL357UZvX7KO6Q=="></script>


	</body>
</html>

