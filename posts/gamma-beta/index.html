<!DOCTYPE HTML>


<script type="text/javascript">
    window.MathJax = {
        tex: {
            inlineMath: [['$', '$']],
            displayMath: [['$$', '$$']]
        }
    };
</script>
<script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.js">
</script>

<html lang="en">
	<head>
	  <title>Connecting Distributions</title>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<meta name="referrer" content="origin">

	

    <meta name="description" content="Senior Data Scientist
Understanding Complexity Through Data and Statistics">
    
    <meta name="generator" content="Hugo 0.138.0">

    
<link rel="stylesheet" href="../../css/main.min.6470f359d96cadb62114d84a859a08e047c933e85d36b945421da8260b62381977f4f70390c7eab26f30d96e167059bdd0e86e799c562d5d4eba32b5a9d4713c.css" integrity="sha512-ZHDzWdlsrbYhFNhKhZoI4EfJM&#43;hdNrlFQh2oJgtiOBl39PcDkMfqsm8w2W4WcFm90OhueZxWLV1OujK1qdRxPA==">


<noscript><link rel="stylesheet" href="../../css/noscript.min.e6f1ba19697eecfddfbf83ff7181b98181998f163d7005f6ae923451556bf85bef357f43dffe1522b92c1efab7fb38441f479e39b7a03e4313a8ef12b0b01f65.css" integrity="sha512-5vG6GWl&#43;7P3fv4P/cYG5gYGZjxY9cAX2rpI0UVVr&#43;FvvNX9D3/4VIrksHvq3&#43;zhEH0eeObegPkMTqO8SsLAfZQ=="></noscript>





    
    
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Connecting Distributions">
  <meta name="twitter:description" content="This short note builds intuition for how several core distributions—Poisson, Exponential, Gamma, Beta, Binomial, Chi Square, Dirichlet, Multinomial—are tightly connected. Rather than treating them as isolated formulas, we view them as different lenses on the same random process: events happening in time or within the same family.">
      <meta name="twitter:site" content="@ericpenax">

    <meta property="og:url" content="https://ericpena.github.io/posts/gamma-beta/">
  <meta property="og:site_name" content="Eric Peña">
  <meta property="og:title" content="Connecting Distributions">
  <meta property="og:description" content="This short note builds intuition for how several core distributions—Poisson, Exponential, Gamma, Beta, Binomial, Chi Square, Dirichlet, Multinomial—are tightly connected. Rather than treating them as isolated formulas, we view them as different lenses on the same random process: events happening in time or within the same family.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-12-21T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-12-21T00:00:00+00:00">
    <meta property="article:tag" content="Statistics">

    
	</head>
	<body class="landing is-preload">

		
			<div id="page-wrapper">

				
          <header id="header">
            <h1><a href="https://ericpena.github.io/">Eric Peña</a></h1>
						<nav id="nav">
							<ul>
								<li class="special">
                  <a href="#menu" class="menuToggle" aria-label='Menu'><span>Menu</span></a>
									<div id="menu">
										<ul>
				              
				              <li><a href="../../">Home</a></li>
				              
				              <li><a href="../../about/">About Me</a></li>
				              
				              <li><a href="../../posts/">Posts</a></li>
				              
										</ul>
									</div>
								</li>
							</ul>
						</nav>
					</header>

<article id="main">
  <header >
    <h2>Connecting Distributions</h2>
    
	</header>
	<section class="wrapper style5">
		<div class="inner">
      <h2 id="a-guided-tour-of-a-tightly-connected-family">A guided tour of a tightly connected family</h2>
<p>This article builds both a <strong>high-level conceptual map</strong> and a <strong>low-level algebraic understanding</strong> of how the following distributions are not isolated objects, but different faces of a small number of underlying stochastic mechanisms:</p>
<ul>
<li>Poisson (counts in time or space)</li>
<li>Exponential (inter-arrival times)</li>
<li>Gamma (waiting time for multiple events; conjugate to Poisson)</li>
<li>Chi-squared (special case of Gamma)</li>
<li>Beta (normalized ratio of Gammas; probability on ([0,1]))</li>
<li>Beta-prime and F (ratios and scaled ratios of Gammas)</li>
<li>Binomial (fixed-(n) Bernoulli trials)</li>
<li>Multinomial (categorical counts)</li>
<li>Dirichlet (multivariate generalization of Beta)</li>
</ul>
<p>The unifying idea is simple but powerful:</p>
<blockquote>
<p><strong>Events happen. We either count them, wait for them, sum their waiting times, or normalize competing rates.</strong></p>
</blockquote>
<p>Once this is internalized, most distributional relationships stop feeling arbitrary. Instead of memorizing PDFs and CDFs, we learn a small set of <strong>transforms, sums, ratios, and conjugacy rules</strong> that generate almost everything we see in applied statistics.</p>


<div class="info-purple">
    <style>
      .info-purple a {
        color: inherit;
        color: #f39c12;
      }
      .info-purple a:hover {
        color: #f39c12;
        font-weight: bold;
      }
    </style>
    <p><strong>Big picture map</strong></p>
<ul>
<li><strong>Poisson ↔ Exponential ↔ Gamma</strong> form a time–count–sum triad.</li>
<li><strong>Beta and Dirichlet</strong> arise by <em>normalizing independent Gammas</em>.</li>
<li><strong>Binomial and Multinomial</strong> are discrete count analogs and are conjugate to <strong>Beta and Dirichlet</strong>.</li>
<li><strong>Chi-square, F, Beta-prime</strong> are reparameterizations or ratios of Gammas.</li>
<li>Many hypothesis tests ultimately reduce to <strong>Gamma algebra + Beta CDFs</strong>.</li>
</ul>
</div>
<script>
document.querySelectorAll('.info-purple a').forEach(function(link) {
    link.setAttribute('target', '_blank');
    link.setAttribute('rel', 'noopener noreferrer');
});
</script>
<hr>
<h2 id="1--from-events-to-counts-to-times">1 — From events to counts to times</h2>
<p>Start with the most primitive object:<br>
<strong>events occur randomly in time at a constant average rate (\lambda)</strong>.</p>
<p>This assumption alone already implies a remarkable amount of structure.</p>
<h3 id="poisson-counting-events-in-a-window">Poisson: counting events in a window</h3>
<p>Let (K(t)) be the number of events observed in a time window of length (t). Then</p>
<p>$$
K(t) \sim \mathrm{Poisson}(\lambda t), \qquad
\mathbb{P}(K = k) = \frac{(\lambda t)^k e^{-\lambda t}}{k!}.
$$</p>
<p>Interpretation:</p>
<ul>
<li>The Poisson distribution answers <strong>“how many?”</strong></li>
<li>The parameter (\lambda t) is <em>expected count = rate × exposure</em>.</li>
<li>Independence and stationarity are baked in: counts in disjoint intervals are independent.</li>
</ul>
<p>This is the natural model for:</p>
<ul>
<li>crashes per mile</li>
<li>failures per hour</li>
<li>arrivals per minute</li>
<li>defects per batch</li>
</ul>
<hr>
<h3 id="exponential-waiting-for-the-next-event">Exponential: waiting for the next event</h3>
<p>Instead of asking <em>how many events occur</em>, ask:</p>
<blockquote>
<p><strong>How long until the next one happens?</strong></p>
</blockquote>
<p>Let (T) be the waiting time to the next event. Then</p>
<p>$$
T \sim \mathrm{Exponential}(\lambda), \qquad
f_T(t) = \lambda e^{-\lambda t}, \quad t &gt; 0.
$$</p>
<p>Key intuition:</p>
<ul>
<li>The Exponential distribution answers <strong>“how long do I wait?”</strong></li>
<li>It is <strong>memoryless</strong>:
$$
\mathbb{P}(T &gt; s+t \mid T &gt; s) = \mathbb{P}(T &gt; t)
$$</li>
<li>Memorylessness uniquely characterizes the exponential distribution.</li>
</ul>
<p>This property is why Exponentials dominate:</p>
<ul>
<li>survival analysis</li>
<li>reliability theory</li>
<li>queueing systems</li>
<li>hazard-rate reasoning</li>
</ul>
<hr>
<h3 id="gamma-waiting-for-multiple-events">Gamma: waiting for multiple events</h3>
<p>Now ask a slightly richer question:</p>
<blockquote>
<p><strong>How long until the (k)-th event occurs?</strong></p>
</blockquote>
<p>Let (T_1, \dots, T_k) be iid Exponential((\lambda)) waiting times. Their sum</p>
<p>$$
S_k = \sum_{i=1}^k T_i
$$</p>
<p>has a Gamma distribution:</p>
<p>$$
S_k \sim \mathrm{Gamma}(k, \lambda)
$$</p>
<p>with density (shape–rate parameterization)</p>
<p>$$
f(x;\alpha,\beta)
= \frac{\beta^{\alpha}}{\Gamma(\alpha)} x^{\alpha-1} e^{-\beta x}, \quad x&gt;0.
$$</p>
<p>Interpretation:</p>
<ul>
<li><strong>Exponential</strong>: waiting for <em>one</em> event</li>
<li><strong>Gamma</strong>: waiting for <em>many</em> events</li>
<li><strong>Poisson</strong>: counting how many events fit into a time window</li>
</ul>
<p>These are not three different stories — they are three views of the <em>same process</em>.</p>
<p><strong>Mental model to keep:</strong></p>
<ul>
<li>Poisson counts events</li>
<li>Exponential times a single event</li>
<li>Gamma times multiple events</li>
</ul>
<hr>
<h2 id="2--gamma-chi-squared-and-f-special-cases-and-ratios">2 — Gamma, Chi-squared, and F: special cases and ratios</h2>
<h3 id="chi-squared-is-just-a-gamma">Chi-squared is just a Gamma</h3>
<p>The Chi-squared distribution is not new; it is a Gamma in disguise.</p>
<p>If</p>
<p>$$
Z \sim \chi^2_{\nu}
$$</p>
<p>then</p>
<p>$$
Z \sim \mathrm{Gamma}\left(\frac{\nu}{2}, \frac{1}{2}\right)
$$</p>
<p>(shape, rate).</p>
<p>This explains why Chi-squared appears everywhere in:</p>
<ul>
<li>variance estimation</li>
<li>likelihood ratio tests</li>
<li>goodness-of-fit tests</li>
</ul>
<p>All of these are ultimately about <strong>sums of squared Gaussian noise</strong>, which collapses into Gamma structure.</p>
<hr>
<h3 id="ratios-of-gammas--beta-prime-and-beta">Ratios of Gammas → Beta-prime and Beta</h3>
<p>Let</p>
<p>$$
X \sim \mathrm{Gamma}(a, 1), \quad
Y \sim \mathrm{Gamma}(b, 1),
$$</p>
<p>independent.</p>
<h4 id="ratio-beta-prime">Ratio: Beta-prime</h4>
<p>The ratio</p>
<p>$$
R = \frac{X}{Y}
$$</p>
<p>has a <strong>Beta-prime</strong> distribution:</p>
<p>$$
f_R(r) = \frac{r^{a-1}}{B(a,b)} (1+r)^{-a-b}, \quad r&gt;0.
$$</p>
<p>This appears naturally when comparing <strong>rates or intensities</strong>.</p>
<hr>
<h4 id="normalized-ratio-beta">Normalized ratio: Beta</h4>
<p>Now normalize instead:</p>
<p>$$
U = \frac{X}{X+Y} \in (0,1).
$$</p>
<p>Then</p>
<p>$$
U \sim \mathrm{Beta}(a,b)
$$</p>
<p>with density</p>
<p>$$
f(u) = \frac{1}{B(a,b)} u^{a-1} (1-u)^{b-1}.
$$</p>
<p>This single transformation explains why Beta distributions dominate probability modeling.</p>
<hr>
<h3 id="f-distribution-as-scaled-gamma-ratios">F distribution as scaled Gamma ratios</h3>
<p>If</p>
<p>$$
X \sim \chi^2_{d_1}, \quad
Y \sim \chi^2_{d_2},
$$</p>
<p>then</p>
<p>$$
F = \frac{(X/d_1)}{(Y/d_2)} \sim F_{d_1,d_2}.
$$</p>
<p>Under the hood:</p>
<ul>
<li>(X) and (Y) are Gammas</li>
<li>Their ratio reduces to a Beta CDF after reparameterization</li>
</ul>
<p>This is why:</p>
<ul>
<li>F CDFs</li>
<li>t-tests</li>
<li>likelihood ratio tests</li>
</ul>
<p>all collapse to <strong>incomplete Beta functions</strong> numerically.</p>
<hr>
<h2 id="3--from-gamma-to-beta-and-dirichlet-normalization-is-everything">3 — From Gamma to Beta and Dirichlet: normalization is everything</h2>
<p>Let</p>
<p>$$
X_i \sim \mathrm{Gamma}(\alpha_i, \beta), \quad i=1,\dots,K,
$$</p>
<p>independent with the <em>same rate</em>.</p>
<p>Define normalized components</p>
<p>$$
p_i = \frac{X_i}{\sum_j X_j}.
$$</p>
<p>Then</p>
<p>$$
(p_1,\dots,p_K) \sim \mathrm{Dir}(\alpha_1,\dots,\alpha_K)
$$</p>
<p>with density</p>
<p>$$
f(\mathbf p) = \frac{1}{B(\boldsymbol\alpha)}
\prod_{i=1}^K p_i^{\alpha_i-1}.
$$</p>
<p>Interpretation:</p>
<ul>
<li><strong>Gamma</strong>: raw, unnormalized “mass”</li>
<li><strong>Dirichlet</strong>: proportions of that mass</li>
<li><strong>Beta</strong>: Dirichlet with (K=2)</li>
</ul>
<p>This is one of the most important constructions in Bayesian statistics.</p>
<hr>
<h2 id="4--binomial--multinomial-and-conjugate-priors">4 — Binomial / Multinomial and conjugate priors</h2>
<h3 id="binomial--beta">Binomial + Beta</h3>
<p>Binomial likelihood:</p>
<p>$$
\mathbb{P}(k \mid n,p) = \binom{n}{k} p^k (1-p)^{n-k}.
$$</p>
<p>Beta prior:</p>
<p>$$
p \sim \mathrm{Beta}(a,b).
$$</p>
<p>Posterior:</p>
<p>$$
p \mid k \sim \mathrm{Beta}(a+k, b+n-k).
$$</p>
<p>Interpretation:</p>
<ul>
<li>successes add to (a)</li>
<li>failures add to (b)</li>
<li>conjugacy = bookkeeping</li>
</ul>
<hr>
<h3 id="multinomial--dirichlet">Multinomial + Dirichlet</h3>
<p>Multinomial likelihood:</p>
<p>$$
\mathbf{k} \sim \mathrm{Multinomial}(n,\mathbf p).
$$</p>
<p>Dirichlet prior:</p>
<p>$$
\mathbf p \sim \mathrm{Dir}(\boldsymbol\alpha).
$$</p>
<p>Posterior:</p>
<p>$$
\mathbf p \mid \mathbf k \sim \mathrm{Dir}(\boldsymbol\alpha + \mathbf k).
$$</p>
<p>Same algebra, higher dimension.</p>


<div class="info-blue">
    <style>
      .info-blue a {
        color: inherit;
        color: #f39c12;
      }
      .info-blue a:hover {
        color: #f39c12;
        font-weight: bold;
      }
    </style>
    <p><strong>Conjugacy checklist</strong></p>
<ul>
<li>Poisson + Gamma → Gamma</li>
<li>Binomial + Beta → Beta</li>
<li>Multinomial + Dirichlet → Dirichlet</li>
</ul>
</div>
<script>
  document.querySelectorAll('.info-blue a').forEach(function(link) {
    link.setAttribute('target', '_blank');
    link.setAttribute('rel', 'noopener noreferrer');
  });
</script>
<hr>
<h2 id="5--how-to-move-around-the-web-recipes">5 — How to move around the web (recipes)</h2>
<ol>
<li>
<p><strong>Counts ↔ times</strong><br>
Poisson ⇔ Exponential ⇔ Gamma</p>
</li>
<li>
<p><strong>Rates → probabilities</strong><br>
Normalize Gammas → Beta / Dirichlet</p>
</li>
<li>
<p><strong>Comparing rates</strong><br>
Ratio of Gammas → Beta-prime / F</p>
</li>
<li>
<p><strong>Discrete counts</strong><br>
Binomial / Multinomial with Beta / Dirichlet priors</p>
</li>
</ol>
<hr>
<h2 id="6--worked-mini-example">6 — Worked mini-example</h2>
<p>Observe (E=5) events in exposure (t=2). Prior:</p>
<p>$$
\lambda \sim \mathrm{Gamma}(\alpha_0,\beta_0).
$$</p>
<p>Posterior:</p>
<p>$$
\lambda \mid E \sim \mathrm{Gamma}(\alpha_0+E,\beta_0+t).
$$</p>
<p>With (\alpha_0=0.5,\beta_0=0):</p>
<p>$$
\lambda \mid E \sim \mathrm{Gamma}(5.5,2),
$$</p>
<p>posterior mean (= 2.75).</p>
<p>Everything here is just <strong>Gamma updating Poisson exposure</strong>.</p>
<hr>
<h2 id="7--what-to-take-away">7 — What to take away</h2>
<h3 id="high-level">High-level</h3>
<p>These distributions form a <strong>single connected system</strong>, not a list.</p>
<h3 id="low-level-moves">Low-level moves</h3>
<ul>
<li>Sum → Gamma</li>
<li>Normalize → Beta / Dirichlet</li>
<li>Count + exposure → Poisson / Gamma</li>
<li>Ratio → Beta-prime / F</li>
</ul>


<div class="info-green">
    <style>
      .info-green a {
        color: inherit;
        color: #f39c12;
      }
      .info-green a:hover {
        color: #f39c12;
        font-weight: bold;
      }
    </style>
    <p><strong>Implementation notes</strong></p>
<ul>
<li>Always check Gamma parameterization (rate vs scale).</li>
<li>Use regularized incomplete Beta for numerical stability.</li>
<li>Prefer log-space for large parameters.</li>
</ul>
</div>
<script>
document.querySelectorAll('.info-green a').forEach(function(link) {
    link.setAttribute('target', '_blank');
    link.setAttribute('rel', 'noopener noreferrer');
});
</script>
<hr>
<h2 id="further-reading">Further reading</h2>
<ul>
<li>Devore, Berk, Carlton — <em>Modern Mathematical Statistics</em></li>
<li>Gelman et al. — <em>Bayesian Data Analysis</em></li>
</ul>
<p>This note aims to replace memorization with a map:
<strong>events → times → sums → ratios → proportions → conjugate updates</strong>.</p>

		</div>
	</section>
</article>
				
					<footer id="footer">
						<ul class="icons">
              
              <li><a href="https://www.linkedin.com/in/eric-pena" class="icon brands fa-linkedin" target="_blank" rel="noopener noreferrer"><span class="label">LinkedIn</span></a></li>
              
              
              <li><a href="https://twitter.com/ericpenax" class="icon brands fa-twitter" target="_blank" rel="noopener noreferrer"><span class="label">Twitter</span></a></li>
              
              
              <li><a href="https://mstdn.science/@ericpena" class="icon brands fa-mastodon" target="_blank" rel="noopener noreferrer"><span class="label">Mastodon</span></a></li>
              
              
              <li><a href="https://github.com/ericpena" class="icon brands fa-github" target="_blank" rel="noopener noreferrer"><span class="label">GitHub</span></a></li>
              
              
              
              
              <li><a href="https://instagram.com/ericpena" class="icon brands fa-instagram" target="_blank" rel="noopener noreferrer"><span class="label">Instagram</span></a></li>
              
              
              
              <li><a href="mailto:eric.pena@binghamton.edu" class="icon solid fa-envelope" target="_blank" rel="noopener noreferrer"><span class="label">Email</span></a></li>
              
              

						</ul>
						<ul class="copyright">
              <li>&copy; 2025 Eric Peña</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
						</ul>
					</footer>

			</div>

      









<script src="../../js/bundle.min.935254271ae3006602cb92b38ba70062a462cefc8d3aa575338369d256bb8422a69fc18f64450e74b7e6c240b20a252f522f3b9f323294bdf9ed466f5fb28ee9.js" integrity="sha512-k1JUJxrjAGYCy5Kzi6cAYqRizvyNOqV1M4Np0la7hCKmn8GPZEUOdLfmwkCyCiUvUi87nzIylL357UZvX7KO6Q=="></script>


	</body>
</html>

